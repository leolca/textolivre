% !TEX TS-program = XeLaTeX
% use the following command:
% all document files must be coded in UTF-8
\documentclass[english]{textolivre}
% build HTML with: make4ht -e build.lua -c textolivre.cfg -x -u article "fn-in,svg,pic-align"

\journalname{Texto Livre}
\thevolume{15}
%\thenumber{1} % old template
\theyear{2022}
\receiveddate{\DTMdisplaydate{2020}{10}{22}{-1}} % YYYY MM DD
\accepteddate{\DTMdisplaydate{2020}{9}{3}{-1}}
\publisheddate{\today}
\corrauthor{William Gottardi}
\articledoi{10.35699/1983-3652.2022.36736}
%\articleid{NNNN} % if the article ID is not the last 5 numbers of its DOI, provide it using \articleid{} commmand
\runningauthor{Gottardi et al.} 
%\editorname{Leonardo Araújo} % old template
\sectioneditorname{Daniervelin Pereira}
\layouteditorname{Anna Izabella Pereira}

\title{Automatic Speech Recognition and Text-to-Speech Technologies for L2 Pronunciation Improvement: Reflections on their Affordances}
\othertitle{Tecnologias de Reconhecimento Automático da Fala e Texto-Fala para o Aprimoramento da Pronúncia em L2: Reflexões das suas Aplicabilidades}
% if there is a third language title, add here:
%\othertitle{Artikelvorlage zur Einreichung beim Texto Livre Journal}

\author[1]{Janaina Fernanda de Almeida \orcid{0000-0003-3747-0279} \thanks{Email: \url{janainafernandadealmeida@gmail.com}}}
\author[1]{William Gottardi \orcid{0000-0002-1291-3953} \thanks{Email: \url{teacher.will@outlook.com}}}
\author[1]{Celso Henrique Soufen Tumolo \orcid{0000-0001-5045-8712} \thanks{Email: \url{celsotumolo@yahoo.com.br}}}
\affil[1]{Universidade Federal de Santa Catarina, Departamento de Língua e Literatura Estrangeiras, Florianópolis, Santa Catarina, Brasil.}

\addbibresource{article.bib}
% use biber instead of bibtex
% $ biber article

% used to create dummy text for the template file
\definecolor{dark-gray}{gray}{0.35} % color used to display dummy texts
\usepackage{lipsum}
\SetLipsumParListSurrounders{\colorlet{oldcolor}{.}\color{dark-gray}}{\color{oldcolor}}

% used here only to provide the XeLaTeX and BibTeX logos
\usepackage{hologo}

% if you use multirows in a table, include the multirow package
\usepackage{multirow}

% provides sidewaysfigure environment
\usepackage{rotating}

% CUSTOM EPIGRAPH - BEGIN 
%%% https://tex.stackexchange.com/questions/193178/specific-epigraph-style
\usepackage{epigraph}
\renewcommand\textflush{flushright}
\makeatletter
\newlength\epitextskip
\pretocmd{\@epitext}{\em}{}{}
\apptocmd{\@epitext}{\em}{}{}
\patchcmd{\epigraph}{\@epitext{#1}\\}{\@epitext{#1}\\[\epitextskip]}{}{}
\makeatother
\setlength\epigraphrule{0pt}
\setlength\epitextskip{0.5ex}
\setlength\epigraphwidth{.7\textwidth}
% CUSTOM EPIGRAPH - END

% LANGUAGE - BEGIN
% ARABIC
% for languages that use special fonts, you must provide the typeface that will be used
% \setotherlanguage{arabic}
% \newfontfamily\arabicfont[Script=Arabic]{Amiri}
% \newfontfamily\arabicfontsf[Script=Arabic]{Amiri}
% \newfontfamily\arabicfonttt[Script=Arabic]{Amiri}
%
% in the article, to add arabic text use: \textlang{arabic}{ ... }
%
% RUSSIAN
% for russian text we also need to define fonts with support for Cyrillic script
% \usepackage{fontspec}
% \setotherlanguage{russian}
% \newfontfamily\cyrillicfont{Times New Roman}
% \newfontfamily\cyrillicfontsf{Times New Roman}[Script=Cyrillic]
% \newfontfamily\cyrillicfonttt{Times New Roman}[Script=Cyrillic]
%
% in the text use \begin{russian} ... \end{russian}
% LANGUAGE - END

% EMOJIS - BEGIN
% to use emoticons in your manuscript
% https://stackoverflow.com/questions/190145/how-to-insert-emoticons-in-latex/57076064
% using font Symbola, which has full support
% the font may be downloaded at:
% https://dn-works.com/ufas/
% add to preamble:
% \newfontfamily\Symbola{Symbola}
% in the text use:
% {\Symbola }
% EMOJIS - END

% LABEL REFERENCE TO DESCRIPTIVE LIST - BEGIN
% reference itens in a descriptive list using their labels instead of numbers
% insert the code below in the preambule:
%\makeatletter
%\let\orgdescriptionlabel\descriptionlabel
%\renewcommand*{\descriptionlabel}[1]{%
%  \let\orglabel\label
%  \let\label\@gobble
%  \phantomsection
%  \edef\@currentlabel{#1\unskip}%
%  \let\label\orglabel
%  \orgdescriptionlabel{#1}%
%}
%\makeatother
%
% in your document, use as illustraded here:
%\begin{description}
%  \item[first\label{itm1}] this is only an example;
%  % ...  add more items
%\end{description}
% LABEL REFERENCE TO DESCRIPTIVE LIST - END


% add line numbers for submission
%\usepackage{lineno}
%\linenumbers

\begin{document}
\maketitle

\begin{polyabstract}
\begin{abstract}
This paper presents a reflection on two technologies - automatic speech recognition (ASR) and Text-to-Speech (TTS) - to improve learners’ pronunciation, aiming for successful spoken communication. It sheds some light on the practical usage of these technologies, demonstrating their effectiveness, qualities, and limitations to assist teachers in deciding the most efficient digital resources applied to their students’ needs. A review of literature on previous empirical studies was carried out, with quantitative and/or qualitative studies conducted by researchers in the field, investigating teachers’ and learners' perceptions and the use of ASR and TTS as a pedagogical tool for pronunciation practice. As a result, it was concluded that a) the presented resources seem to have the potential to enhance pronunciation practice, both in terms of perception and production; b) technology can result in considerable benefits to learners, mainly as a supplement to pronunciation teaching; and c) the use of these digital resources is a way of giving learners the opportunity to focus on their specific difficulties and receive personalized feedback while becoming more autonomous in their learning process.

\keywords{Automatic Speech Recognition \sep Text-to-Speech \sep CALL \sep Pronunciation Teaching \sep Pronunciation Improvement}
\end{abstract}

\begin{portuguese}
\begin{abstract}
Este artigo apresenta uma reflexão sobre duas tecnologias - reconhecimento automático da fala (ASR – Automatic Speech Recognition) e texto-fala (TTS - Text-to-Speech) - para aprimorar a pronúncia dos alunos, visando uma comunicação oral competente. O trabalho explora o uso dessas tecnologias, demonstrando sua eficácia, qualidades e limitações para ajudar os professores a decidirem os recursos digitais mais eficientes aplicados às necessidades de seus alunos. Foi realizada uma revisão bibliográfica de estudos empíricos prévios, com pesquisas quantitativas e / ou qualitativas realizadas por pesquisadores da área, investigando as percepções de professores e alunos e o uso de ASR e TTS como ferramentas pedagógicas para o ensino de pronúncia. Como resultado, concluiu-se que a) os recursos apresentados demonstram ter potencial para aprimorar a prática da pronúncia, tanto em termos de percepção como produção; b) a tecnologia pode resultar em benefícios consideráveis para os alunos, principalmente como um suplemento ao ensino de pronúncia; e c) o uso desses recursos digitais é uma forma de dar aos alunos a oportunidade de focar em suas dificuldades específicas e receber um retorno personalizado, tornando-se mais autônomos em seu processo de aprendizagem.

\keywords{Reconhecimento Automático da Fala \sep Texto-Fala \sep Síntese de Fala \sep CALL \sep Ensino de Pronúncia \sep Aprimoramento de Pronúncia}
\end{abstract}
\end{portuguese}
% if there is another abstract, insert it here using the same scheme
\end{polyabstract}

\section{Introduction}\label{sec-intro}
Spoken communication to be effective must consider pronunciation as a fundamental part of it \cite{pennington2019} since the primary medium of language is speech \cite{slabakova2016}. Therefore, when it comes to second language acquisition (SLA), we must consider the different dimensions of second language (L2) speech: intelligibility, comprehensibility, and accentedness. Concerning intelligibility, \textcite[p. 189]{munro1995} broadly define it as “the extent to which a speaker’s message is actually understood by a listener, but there is no universally accepted way of assessing it”. It differs from comprehensibility – the listener’s evaluation of difficulty in understanding another person’s speech, and from accentedness – the distinction of the pronunciation of a sentence sounds in comparison to an expected production pattern \cite{munro2006}.

For some authors, the goal of L2 pronunciation teaching and research should be enhanced intelligibility and comprehensibility instead of native-likeness \cite{obrien2018}, since “rather than requiring native-sounding oral output, L2 users need intelligible speech” \cite[p. 213]{munro2008}. Moreover, pronunciation difficulties in an additional language can compromise intelligibility, which may also hinder comprehension, compromising oral communication \cite{sicola2015}. Although pronunciation plays a critical role in successful communication, pronunciation teaching is sometimes neglected due to time constraints and insecurity regarding how to get started \cite{roccamo2014}. Furthermore, pronunciation is connected to identity issues and language attitudes, for both learners and teachers, which might impact teachers’ confidence and willingness to teach pronunciation \cite{pennington2019}.

In order to strengthen the potential benefits of pronunciation teaching, learners’ attention should be directed to those aspects that are likely to most affect their oral performance. According to \textcite{derwing2018}, it is only possible to value the effectiveness of pronunciation teaching if it improves communication in general; that is, once the pedagogical intervention helps to increase learners’ intelligibility and comprehensibility. Therefore, the objective of this paper is to present a reflection on two technologies - automatic speech recognition (ASR) and text-to-speech (TTS) - to improve learners’ pronunciation, aiming for successful spoken communication. For this purpose, the reflection will address the affordances of the technologies by reviewing both quantitative and qualitative pieces of research from authors in the field.

To start with, the following section will detail recent empirical findings on pronunciation teaching, especially as a means to draw learners’ attention to L2 phonological forms of the target language input. By focusing on these aspects, learners can achieve improvements in their L2 pronunciation skills in order to reduce communication breakdowns due to inaccuracy in speech perception or production and, in turn, enhance speech intelligibility and comprehensibility.

\section{Pronunciation instruction}\label{sec-2}
In the past few years, several studies focusing on L2 pronunciation teaching have been carried out, reporting benefits for the acquisition of both segmental and suprasegmental features\footnote{Segmental features are the phonetic features at the segment level, distinguishing the sounds of a given language (e.g., vowels and consonants). In contrast, suprasegmental features are those beyond the level of individual sounds, such as stress and intonation \cite{yavas2011}.} \cite{thomson2015}. This section aims to consider recent claims on the discussion of pronunciation teaching, defending it as a means to help L2 learners overcome difficulties in their pronunciation skills that otherwise could affect overall communication in the target language. Although there is also a great deal of current discussion concerning which pronunciation feature yields more significant pronunciation gains, the comparison of the specific results for suprasegmental or segmental instruction is beyond the scope of this study (for a review, see \textcite{gordon2016, lee2020, zhang2020}). However, a significant finding from previous research is that pronunciation instruction tends to lead to more improvement gains when employing explicit techniques rather than implicit ones \cite{thomson2015, gordon2016}.

Such a finding endorses discussions on the role of oral input for L2 learning. In general terms, input is the language embedded in the communication contexts to which learners are exposed during their learning process \cite{vanpatten2019}. Accordingly, it is common knowledge that oral input is crucial for acquiring the target language phonology \cite{tyler2019}. More specifically, input is a prerequisite for the development of learners’ perceptual skills as it provides the phonological data for one to perceive the L2 sounds \cite{liakin2017, tyler2019}.

However, when it comes to instructional language learning settings, language input is somehow limited in terms of quality or/and quantity. As observed by \textcite{munoz2008}, the exposure to the target language is restricted to short class sessions, and it comes primarily from the teacher and peers, who usually share the same L1. Therefore, considering the lack of frequent language input and the reduced opportunities for practicing oral skills \cite{carlet_improving_2018}, L2 learners may not be able to fully develop their L2 pronunciation skills only through the limited contact with the target language provided in class.

In order to ensure learning, exposure to the target language has to provide access to comprehensible input, that is, learners need to make sense of the language instances that are being presented. According to \textcite[p. 46]{vanpatten2019}, the term comprehensible input is associated with Krashen’s ideas (proposed in the late 1970s), and it is based on the assumption that “during the act of comprehension, learners are engaged in mapping meaning onto form”. Therefore, on one hand, input is only effective for L2 acquisition if the learner can comprehend it, or else the internal mechanism cannot use the presented data to extract its meaning. On the other hand, as learners process input primarily for meaning \cite{vanpatten2008}, their focal attention on the phonological aspects of the language is likely to be diminished.

Under these circumstances, pronunciation teaching appears to be crucial in overcoming the shortcomings of classroom settings. Following \textcite{thomson2015} conclusion, explicit teaching is likely to have a positive impact on the acquisition of phonological forms because “it orients learners’ attention to phonetic information, which promotes learning in a way that naturalistic input does not” (p. 340). Consequently, learners who are more aware of the underlying phonological forms are inclined to achieve a more target-like performance at both perception and production levels \cite{carlet_improving_2018}.

According to \textcite[p. 104]{carlet_improving_2018}, L2 phonological awareness “can be developed through any activity that brings a specific aspect into the language learners’ consciousness”. The authors also provide some examples of consciousness-raising activities reported in the literature, such as the explicit comparison between the L1-target language phonologies, input enhancement, and feedback techniques. Ultimately, the authors defend that helping learners to raise their awareness of the target language phonology “does not only positively reflect on their L2 pronunciation, but also enables them to take control of their pronunciation learning by developing self-monitoring abilities” \cite[p. 104]{carlet_improving_2018}.

In a similar vein, \textcite{darcy2018} stresses that feedback is also a predictor of self-awareness pronunciation development, mainly because it indicates specific difficulties to the learner as they occur. However, due to the different types of feedback, the author points out that explicit feedback should be favored when pronunciation aspects are taught as an integrated part of a lesson. Therefore, explicit feedback helps to clarify that the correction is about a particular form rather than meaning. In this manner, it is possible to draw the learners’ attention to their production compared to what they were expected to produce. In response, learners can focus on monitoring their pronunciation in order to achieve a more intelligible and comprehensible speech.

Learners’ production also plays a pivotal role in pronunciation learning since output is crucial for this skill improvement \cite{demenko2010}. Output also has the function of promoting automaticity, freeing limited cognitive resources (e.g., working memory, and attention), and letting them available to other language acquisition processes \cite{grass2015, ortega2009}. In addition, like any other skill, practice leads to proceduralized knowledge and, after consistent practice, procedural knowledge becomes automatic knowledge, which facilitates a fluent and spontaneous speech \cite{dekeyser2015}.

Considering the discussion above, pronunciation aspects should be explicitly taught as early as possible in the learning process \cite{darcy2018, derwing2018}, along with activities aiming at developing learners’ awareness of the specific forms and their own oral performance. Also, the efficiency of pronunciation teaching should be built on the three main ‘ingredients’ of explicit and communicative activities - containing or not repetition (focalizing on both form and meaning) - of focus on perception, and of explicit feedback \cite{darcy2018}. Thus, in agreement with \textcite{thomson2015} that informed instruction combined with practice opportunities will help learners improve speech production and considering the importance of pronunciation to spoken communication and pronunciation teaching to SLA, all the resources available to help accomplish the goal of pronunciation development are welcome. In this matter, digital resources can be beneficial to teachers and learners, as explored in the next section.

\section{Technology and pronunciation teaching}\label{sec-3}
Language classrooms without any form of technology would create a limited and artificial learning environment once technology has been so interwoven and pervasive in human activities \cite{chun2016}. However, the usage of technology during the lessons does not make inefficient pedagogy efficient \cite{golonka2014}.

Considering the importance of reflecting on the usage of digital technology for L2, there is a specific subfield of Applied Linguistics that studies the relationship between technology and SLA called Computer-Assisted Language Learning (CALL) \cite{martins2012}. \textcite[p. 261]{davies2006} defines CALL as “an approach to language teaching and learning in which computer technology is used as an aid to the presentation, reinforcement, and assessment of material to be learned, usually including a substantial interactive element.”. This field has grown quickly in recent decades \cite{pennington2019} and it comprehends a wide array of practices, which predicts equally varied outcomes and pedagogical effectiveness \cite{chapelle2013}. This tension between technology and pedagogy is a key issue concerning the topic \cite{rogerson-revell2021}. For this reason, we now turn our focus on the two technologies with supporting evidence for L2 pronunciation improvement along with some classroom implications. In \cref{sec-3.1}, we explore automatic speech recognition (ASR) technology as an additional resource for learners to produce more oral output with explicit feedback; and in \cref{sec-3.2}, we present text-to-speech (TTS) technology and its affordances for pronunciation improvement, focusing on input, that is, “the sine qua non of acquisition” \cite[p. 177]{grass2015}.

\subsection{Automatic Speech Recognition and Its Affordances for Pronunciation Improvement}\label{sec-3.1}
ASR can be defined as “an independent, machine-based process of decoding and transcribing oral speech” \cite[p. 316]{levis2013}. By building a string of words from an acoustic signal, it can be applied to dictation (a single specific speaker’s monologue transcription) tools, or human-computer interaction \cite{jurafsky2020}, such as Intelligent Personal Assistant (IPA) embedded to smart devices (e.g., smartphones and smart speakers) \cite{inceoglu2020, moussalli2020}. This technology started to be developed by the late 1940s and early 1950s. However, it has been constantly enhanced due to the development of new model techniques and algorithms, improvement in noisy speech recognition, and the demand to integrate it into mobile devices \cite{jurafsky2020, levis2013}.

ASR technology applied to a CALL context has been criticized by some authors in the past decade due to its incapacity to comprehend L2 speech accurately at a similar rate as human listeners \cite{derwing2000, kim2006, levis2013}, its much lower accuracy scores for nonnative speakers than those for native speakers \cite{ashwell2017, rogerson-revell2021}, and its insufficient or even incorrect feedback \cite{chen2011, demenko2010, levis2013, rogerson-revell2021}. On the other hand, recent research has shown that this technology has been improving in the past years \cite{ashwell2017, dizon2020, dizontang2020, mccrocklin2020, moussalli2020, bogach2021}. Furthermore, \textcite[p. 61]{ashwell2017} argue that “these systems are continually improving on their respective accuracy rates by constantly gathering acoustic information and utilizing machine learning”.

ASR systems usually use a native speaker as a model from a database containing a vast number of native speaker speech samples. Although it has been advancing in recent years, especially considering native speaker recognition, the accuracy level for nonnative speech is considerably lower \cite{rogerson-revell2021}. Notwithstanding, in a recent study exploring the accuracy of Google Voice Typing, a free ASR-based dictation tool, considering native and nonnative English speakers’ samples, \textcite{mccrocklin2020} concluded that “across all L2 speech samples, there was a statistically significant relationship between Google recognition and human listener’s intelligibility as well as ratings of comprehensibility” (p. 1092). The authors calculated descriptive statistics over 60 sentences produced by the participants of the study. Each speaker dictated each sentence twice to a Google Document. The participants were divided into three groups according to their L1 – English L1 (n = 10), Spanish L1 (n = 10), and Mandarin Chinese L1(n = 10). The results show an accuracy rate of 96.2\%, 92.7\%, and 90.9, respectively. The authors state that “whereas earlier research found recognition of nonnative speech 18–20\% lower than native speech, Google has reduced that gap to 3–5\%.” (p. 1094).

In a different study, \textcite{ashwell2017} investigated how accurately Google Web Speech API could recognize the speech of Japanese learners of English as a foreign language (EFL). Participants produced 13 sentences containing specific grammatical features as an elicited imitation test. They found that the system had an overall recognition accuracy of 89.4\%. They concluded that the pronunciation of specific sounds is the most problematic issue for the systems to perform the speech recognition process if compared to native speaker input. In addition, they affirm that pronunciation issues may not be a barrier for ASR systems and this technology could be used for assessing student’s grammatical ability.

Following a pedagogical point of view, \textcite{inceoglu2020} explored the usefulness of ASR pronunciation practice to check its effects on learner’s production in a segmental level as well as the learners’ perception of the usage of ASR as a learning tool. A total of 19 Korean university students produced 28 minimal pair sentences containing vowel contrasts in a pretest and posttest study design. Results of acoustic analysis showed a meaningful improvement in some vowels, but no changes in others. However, the great majority of the participants indicated that ASR is useful for pronunciation practice.

Considering learner’s perception, \textcite{mroz2018} investigated how 16 learners of French as a foreign language using ASR in Gmail developed greater awareness of their own intelligibility. The author followed a qualitative approach analyzing participants’ responses to semistructured interviews. The results show that most participants considered ASR to be a relevant diagnostic tool once they could assess the gaps and successes in their intelligibility by using such technology.

Moreover, \textcite{golonka2014} reviewed over 350 studies to comprehend the learning and teaching effectiveness of technology use. The authors reviewed empirical studies that compared the use of newer technologies to traditional materials and methods. The review considered individual study tools (e.g., grammar checker, ASR, electronic dictionary, and pronunciation programs), classroom-based technologies, mobile devices, and network-based social computing. They found strong support for a positive impact of ASR programs on foreign language (FL) learning and teaching. In addition, they affirmed that “ASR technology can facilitate improvement in pronunciation to a larger extent than human teachers can and […] ASR programs have great potential in FL learning” (p. 88).

Furthermore, ASR can be applied in varied ways to facilitate the learning process, inside and outside the classroom \cite{kim2006, chen2011, levis2013, golonka2014, ashwell2017, liakin2017, mroz2018, dizon2020, dizontang2020, inceoglu2020, mccrocklin2020, rogerson-revell2021}. To put it concisely, based on the aforementioned studies, ASR tools can contribute to pronunciation improvement by:

\begin{itemize}
    \item allowing the development of L2 learners’ autonomy, offering an opportunity for learners to work on their pronunciation individually, at a self-selected pace;
    \item encouraging learners to produce more output in a low-anxiety environment, talking to a tireless listener (the algorithm);
    \item helping learners to improve not only their pronunciation but also their oral communication skills, speaking fluency, and accuracy;
    \item increasing learners’ confidence and motivation, by engaging students in the process of learning and fostering a more positive attitude towards it;
    \item providing learners with the opportunity to receive pronunciation feedback outside the language classroom (from the application);
    \item enabling ubiquitous, out-of-class learning, which allows learners to decide when, what, and how to learn;
    \item enabling learners to interact with IPAs (e.g.: Siri, Microsoft Cortana, or Google Assistant), performing spontaneous, meaningful, and authentic communicative tasks, also offering an opportunity to test their ability to produce intelligible speech; and
    \item facilitating the extensive practice of segmental and suprasegmental features of the language, from minimal pair to mirroring famous speeches or rehearsing presentations.
\end{itemize}

Besides all these contributions, ASR offers limitless opportunities to practice oral output. As mentioned in section 2.1, output plays a pivotal role in second language acquisition processes. ASR is, therefore, a versatile resource that can be used to transcribe an audio file to text, automatically generate subtitles in a video on YouTube, interact with a smart device using voice commands, practice pronunciation autonomously through mobile applications and use dictation programs. Moreover, it is responsive to different learning goals and adaptable to any language curriculum. As \textcite{yoshida2018} points out, ASR has become available in different programs as built-in features. Many programs are available for free on the internet (e.g.: Google Docs’ voice typing, Microsoft Word’s dictation tool, or Google and Bing’s voice search). Some of them do not even require an internet connection (speech recognition in Windows 10, for instance).

This extended practice that ASR places at disposal is “especially significant for learners who have little to no access to other L2 speakers outside of class” \cite[p. 108]{dizontang2020}, and hence with less opportunities to practice their oral skills in general. By practicing with the ASR program, the listener will be the algorithm that transcribes the learner’s utterances. Thus, learners can check to which extent the application could understand their speech and keep practicing until the software transcribes the intended utterance correctly, that is, their speech was intelligible to the application and the communicative purpose was fulfilled. Although ASR is an additional tool for learning and does not substitute social interaction, this oral practice is of paramount importance once “many individuals in EFL settings have a strong need to improve their oral abilities” \cite[p. 60]{chen2011}.

Furthermore, the overall teachers and students’ perceptions of ASR applied to teaching and learning demonstrate a bright future for this technology. \textcite[p. 319]{levis2013} state that many studies indicate that “software that includes ASR is a huge plus to language learners in terms of practice, motivation, and the feeling that they are actually communicating in the language rather than simply repeating predigested words and sentences”. This is congruent with the results of other studies based on the perception of both students and teachers that yield positive reactions towards ASR \cite{chen2011, inceoglu2020}. In addition, this positive reaction might be connected to the fact that learners comprehend the importance of pronunciation for successful communication, being keen to use technological resources to improve it \cite{rogerson-revell2021}.

All in all, the potential of ASR for pronunciation improvement in second language acquisition is enormous. Although “ASR will never be 100\% accurate” \cite[p. 1641]{knill2018}, teachers and learners can focus on the strengths of this technology to fulfill specific learning goals. ASR can provide learners with the opportunity to produce oral output and therefore practice pronunciation and speaking skills. \textcite{chapelle2008} define the latter skill as "a fast-paced mental and physical activity that requires the speaker to process linguistic knowledge automatically” (p. 151). Therefore, ASR could also be used for practicing such skill.

\subsection{Text-to-Speech and Its Affordances for L2 Pronunciation Improvement}\label{sec-3.2}
Considering the central role of oral input for the development of perceptual skills and infrequent exposure to it in instructional contexts, as discussed in section 2.1, pronunciation teaching also needs to focus on the level of perception. However, according to \textcite{darcy2018}, to avoid class time overload and monotonous tasks, three aspects must be considered in perceptual listening activities: 1) contextualized and repeated links to the vocabulary that is already being studied (rather than in unknown words such as minimal pairs); 2) variability in the input, by exposing learners to different accents, voices, and speech rates, for instance; and 3) multimodality, that is, presenting the language instances in more than one modality (e.g., oral input plus written input).

Following this perspective, TTS, also called speech synthesis, is one specific technology to enhance perceptual knowledge. Straightforwardly, \textcite{handley2013} defines speech synthesis as “the process of making the computer talk” (p. 5846), and it is a widely used technology that automatically generates synthesized speech from units of written text displayed on a screen \cite{liakin2017}. Currently, there is a variety of TTS programs either as free or paid versions, which may differ in some of their functions, as more sophisticated versions usually offer voice options (e.g., male or female, native or nonnative-like, different language varieties and accents), more interaction to the user, such as highlighting each word being read aloud, and more access to other types of files (e.g., PDFs, e-books, and web documents) \cite{moon2012}.

Although this technology is not recent, it has received significant improvement over the last few years in order to become more similar to natural human speech \cite{handley2013, liakin2017, moon2012}. Along with the advances, TTS has attracted scholars’ attention as a potential pedagogical tool, especially concerning whether and how it could assist L2 classes due to potential uses for different aspects of language learning. For example, \textcite{moon2012} proposes that TTS provides several opportunities for practicing all four skills: writing, reading, listening, and speaking. For illustration, the author suggests its use for learners to 1) revise their written texts; 2) create and download audio versions from any text for listening to a topic of interest; 3) adjust the speed and pace of the audio in order to facilitate understanding of the content being read; 4) elaborate and practice dialogues with different English accents; and 5) check on the pronunciation of individual words.

In addition, \textcite{handley2013} points out that TTS has more applicable and apparent benefits for some language domains. As an example, the technology can help in exercises to reinforce the relationship between graphemes and phonemes of the target language, which could supplement writing and reading abilities, and, therefore, widen learners’ vocabulary knowledge.

More recently, some attention has been given to analyzing TTS speech quality in research \cite{liakin2017}. For instance, \textcite{cardoso2015} investigated if it could generate speech like human performance under four aspects: comprehensibility, naturalness, pronunciation accuracy, and intelligibility. To answer the question, the authors recruited 15 undergraduate students to rate oral samples provided either by TTS or by human recordings on two conditions: only sentences or within a story. Participants were also engaged in an identification task to focus on the past form of regular verbs in English, in which they should judge if the sentences contained or not the target grammar feature. A sequence of paired t-tests sample was run, revealing a significant difference in the overall scores of human and TTS oral productions on both conditions (story and sentences). However, the tests showed no significant differences between the samples in the identification task. Likewise, it is worthy of mention that, despite not achieving an equal baseline as the human recordings, participants assigned relatively high scores to the TTS samples under the dimensions of comprehensibility, pronunciation accuracy, and intelligibility in both conditions. These results indicate, therefore, that the synthesized voice generated by the technology can currently constitute an adequate source of spoken input for L2 learners.

As cited by \textcite{liakin2017}, the authors' findings indicate that the quality of the synthesized voice can resemble the human voice, allowing its use as a pronunciation model. \textcite{grimshaw2018} obtained similar results when analyzing the output of five different TTS applications. The study showed that the participants' overall ratings for comprehensibility were relatively high, although scores for the naturalness dimension were well below comprehensibility. In addition, two aspects can be pointed out from this study. First, as language users become more familiar with the specific synthesized voice, they can perceive speech as more understandable and natural \apud{bione2017}{grimshaw2018}. This implies that, if implemented on a recurring basis as a pedagogical resource, the output generated by TTS may be perceived with better quality. Second, considering the variability still present among TTS applications, it might be necessary to assess the speech quality of whichever application before using it as a pedagogical tool.

The study conducted by \textcite{liakin2017}, which aimed to investigate students' perception of both ASR and TTS as pedagogical tools, equally supports the use of TTS as an additional source of oral L2 input. The authors reported a previous experiment in which participants were divided into different groups and engaged in weekly teacher-led or technology-led practices (with ASR or TTS). After the experimental period, the authors asked the participants from the ASR group (n=14) and TTS group (n=9) to take part in a survey and an interview, inquiring about their attitudes and perceptions of the tools for pronunciation practice. The data from the survey was quantitatively analyzed through descriptive statistics and revealed, overall, that "the participants evaluated positively their experience with these two mobile speech technologies and, more importantly, they found them useful, practical and helpful for their own learning" (p. 21). Likewise, the qualitative analysis from the interviews corroborates most findings from the quantitative data, evidencing the learners' positive attitudes towards the use of the tools once again.

With more specific reference to TTS technology, participants' responses collected in the interview acknowledged some of the aforementioned possibilities to take advantage of the tool, such as extensive listening and oral comprehension practices. Besides the perception practice, some learners also noticed an improvement in their pronunciation after using TTS. According to the authors, such a gain is "explained by the fact that the app increased their exposure and access to the correct pronunciation model" \cite[p. 24]{liakin2017}.

These research findings indicate that TTS technology seems ready to be used in L2 classes. It has much to offer for pronunciation practice, “particularly as a supplemental source of input which can cater for learners’ individual needs and interests” \cite[p. 112]{cardoso2015}. Moreover, \textcite{cardoso2018} has empirically attested to such a claim in a study designed to analyze the use of TTS in learning the pronunciations of the past tense marker of regular verbs in English. The participants of the study received a four-week treatment similar in numbers of activities but different in the feedback provided, either by TTS or by the language teacher. In a pre-post-test design, the author observed that both groups (TTS and Non-TTS) obtained similar scores, showing that TTS could be implemented as an out-of-class teaching tool to “increase in-class time so that teachers and students could focus on other important tasks” \cite[p. 21]{cardoso2018}. The author, however, stresses that in this experiment, the use of the TTS enhanced pronunciation at the level of perception. A possible positive effect of this enhanced pronunciation is that learners can engage in other speaking activities so as to transfer the obtained perceptual knowledge into production.

In this regard, \textcite{eksi2016} were able to report production gains after engaging participants in a rehearsing session to practice an oral presentation with the help of TTS programs. The authors recruited 43 EFL teacher trainees to participate in an experimental instruction, preceded and followed by a testing section. At the end of the experiment, the participants also filled in a post reflection questionnaire to assess their impressions regarding using the tools in their self-studies. The pre- and post-tests consisted of five-minute-long oral presentations delivered by each teacher trainee, which were recorded and rated according to five aspects (fluency, pronunciation and accent, vocabulary, accuracy, and content). The scores obtained from the tests reveal a significant difference when analyzing the teacher trainees’ scores and their overall pronunciation and fluency performance in the post-test, suggesting that TTS was indeed helpful to promote pronunciation improvements. Likewise, the participants’ reflection on the questionnaire acknowledged the user-friendly interface of the application and their willingness to make use of this technology, as most of them expressed the intention to keep using it in self-studies.

Concerning attitude towards using TTS, students seem to be willing to use it in their learning process. \textcite{bione2016} analyzed the perceptions of fifteen Brazilian learners of EFL about the quality of texts generated by TTS and concluded that “EFL learners have overall positive attitudes towards the pedagogical use of TTS, and that they would like to use the technology as a learning tool” \cite[p. 50]{bione2016}.

Given these research findings, language teachers and instructors have a lot to benefit from TTS. As seen, this technology can provide limitless oral input in the target language \cite{cardoso2015}, promote efficient and personalized feedback \cite{cardoso2018}, raise learners’ awareness to specific features and forms of the L2 \cite{liakin2017, araujogomes2018} and increase learners’ autonomy in their own phonological development \cite{moon2012, liakin2017}.

However, in order to enhance gains at the production level as well, it would be more appropriate to combine the use of TTS with other tools that elicit speech production on the users’ part. Hence, \textcite{liakin2017} suggest combining both ASR and TTS as an “anytime anywhere mobile learning setting” seems to be a promising proposal to facilitate pronunciation improvement. In the following section, we further discuss the combination of these technologies and suggest some digital resources to explore these technologies for pedagogical purposes.

\subsection{Integrating ASR and TTS to Pronunciation Teaching}\label{sec-3.3}
The previous sections demonstrated the affordances of both ASR and TTS technologies for pronunciation teaching and learning. All things considered, it is possible to reason that these technologies can foster pronunciation improvement inside (under the teacher's guidance) and outside (autonomously by the learner) the classroom. \textcite{liakin2017} argue that researchers have only started to explore the pedagogical uses of TTS and ASR in L2 education; notwithstanding, the available studies so far suggest positive results as a classroom instruction complement after their extended use. Similarly, \textcite{levis2013} indicate that the connections between ASR and text-to-speech software have not been fully explored, and that they can have promising results for non-native speech applications.

Considering the learner’s side, \textcite{golonka2014} state that technological innovations can provide learners with interaction opportunities, feedback, and more contact with the target language, besides increasing their motivation and interest. Such a statement is also congruent with students’ perceptions regarding ASR and TTS programs. In this regard, \textcite{liakin2017} observed comparative results when investigating learners' impressions on the use of both technologies. According to the authors, the participants not only recognized the pedagogical importance of ASR and TTS but also enjoyed the mobile-enhanced learning environment afforded by them.

Turning our focus to pronunciation teaching, these two technologies can be combined to provide learners with relevant oral input (TTS), opportunities to practice oral output (ASR), and the opportunity to check their production in relation to the perceptual knowledge they have acquired. Thus, this blended usage can be a powerful resource for L2 language teachers. For instance, it is possible to use these digital resources to offer relevant extra-class activities once they can make it easier to assign beneficial self-administered pronunciation tasks \cite{munro2015}.

Another relevant pedagogical implication is that ASR and TTS can facilitate integrating the pronunciation component in all sorts of language courses, as defended by \textcite{darcy2021} and \textcite{gordon2016}. In line with the authors’ view, pronunciation gains can be achieved even in short periods of instruction, without the (actual) need to devote a whole course to pronunciation instruction. Rather, it is viable to allocate some focus on both segmental and suprasegmental features within their communicative classes \cite{darcy2021}. As a result, having recurrent pronunciation practice is likely to yield significant gains on the learners’ pronunciation skills. Furthermore, ASR and TTS programs can be employed whenever specific sounds and features are taught in class to back up the practice of the target aspects. In this way, their use can be adapted for different learning units throughout a course or school year.

Moreover, both programs allow for individualized instruction, a core standpoint of the Intelligibility Principle for pronunciation teaching \cite{thomson2015, munro2015}. In agreement with the principle, it is advisable to evaluate the instruction needs according to the learner's specific demands, especially concerning the aspects likely to hinder their intelligibility. Hence, in a classroom environment, resorting to digital resources is an alternative way to tailor a more individualized instruction. This is especially relevant with regard to the time constraints teachers face in complying with the regular curriculum, enabling them to devote more class time to the difficulties shared by a greater number of students \cite{roccamo2014, munro2015}.

In a more practical vein, there are many digital resources available for free that use both ASR and TTS technology. A simple way to use them is by voice web search (e.g., \url{https://www.google.com}). The intended message is dictated on the textbox after clicking on the microphone icon, and the result is read out-loud by the TTS tool. Another possibility is an online translator (e.g., \url{https://translate.google.com/}). Instead of typing words, it is possible to dictate them to the program, or discover the translation into the target language and listen to its pronunciation \cite[for a more detailed guideline, see]{carrier2017}. For instruction focused on form\footnote{Focus on form refers to drawing learners’ attention to linguistic elements encountered in lesson \cite{long1991}.}, an immersive reader (e.g., Microsoft Word\footnote{\url{https://support.microsoft.com/en-us/office/listen-to-your-word-documents-5a2de7f3-1ef4-4795-b24e-64fc2731b001}. Accessed: Dec 12th, 2021.}, Microsoft Edge\footnote{\url{https://support.microsoft.com/en-us/topic/use-immersive-reader-in-microsoft-edge-78a7a17d-52e1-47ee-b0ac-eff8539015e1}. Accessed: Dec 12th, 2021.}) can provide the target form while an ASR-based dictation tool (e.g., \url{https://dictation.io/}, \url{https://speechnotes.com}) can be used for the output drills\footnote{Asking students to repeat individually an intended utterance to practice specific linguistic elements \cite{harmer2012}.}. Thus, teachers can invest more time in encouraging communicative activities with the low-level basic pronunciation drills done with the ASR software \cite{kim2006}.

Similarly, VoiceNotebook’s\footnote{\url{https://voicenotebook.com/prononce.php}} pronunciation practice page not only integrates both ASR and TTS in a single webpage but also includes a playback feature. It also displays a comparison between a target text passage with the transcribed utterances from the ASR tool, proving better feedback for the learner to focus on their main difficulties.

It is worth mentioning that the ASR and TTS as well as their pedagogical implications can be applied for different learning contexts and different languages. As \textcite{henrichsen2021} indicates, ASR technology can convert speech into text in over one hundred languages. Moreover, the aforesaid ways to use the tools can be applied to different target languages if supported by the applications.

As a final statement, based on the definition of efficient pronunciation teaching by \textcite{darcy2018}, as aforementioned, it is possible to fulfill all those ‘ingredients’ by combining both technologies: ASR can be an integrative part of different explicit and communicative activities providing learners with endless opportunities of producing oral output, TTS can be used to develop learners' perception and ASR can provide automatic explicit feedback at the learner’s pace. Hence, the combined use of both technologies can be an attractive option for the long sought pronunciation improvement.

\section{Final Remarks}
The discussion in this paper aimed to present the affordances of ASR and TTS for L2 pronunciation improvement. For this purpose, a review of literature on previous empirical studies was carried out, with research investigating learners and teachers’ perceptions and the use of ASR and TTS as a pedagogical tool for pronunciation practice.

Given that pronunciation inaccuracies can result in communication breakdowns, language users may have to improve their pronunciation abilities in order to deliver and comprehend L2 speech more efficiently. However, as seen, it is not so simple to tailor pronunciation instruction in a classroom environment, mainly due to time constraints. Hence, the technological resources presented – ARS and TTS – can facilitate pronunciation practice, in terms of both perception and production. Unfortunately, even the most advanced applications for pronunciation practice “are still lacking explicit feedback for acquisition and assessment of foreign language suprasegmentals” \cite[p. 3]{bogach2021}. Therefore, these tools might be more appropriate for practicing segmental features of the language if used as an autonomous learning tool without the guidance of a teacher.

As the aforementioned studies suggest, technology can result in considerable benefits to learners, mainly as a supplement to pronunciation teaching. Nonetheless, these benefits can only be achieved if the teacher is aware of “what their students need, and if they use tools that have been shown to be effective” \cite[p. 326]{darcy2018}. Thus, the use of technological resources is not to replace the important role of the teacher. Rather, it is a way of giving learners the opportunity to focus on their specific difficulties and receive personalized feedback while becoming more autonomous in their learning process, meaning that “learning is not limited to the classroom context” \cite[p. 104]{carlet_improving_2018}.

All being said, these technologies hold a bright future in CALL. However, “educational technology is only as good as the humans behind it” \cite[p. 201]{rogerson-revell2021}. Hence, this paper sought to shed some light on the usage of two prodigious technologies, demonstrating their effectiveness, qualities, and pitfalls to assist teachers in their pedagogical decisions to meet their students’ needs. Notwithstanding, the best tools may “not necessarily [be] those that seem newest, coolest, or ﬂashiest” \cite[p. 209]{yoshida2018} but the most adequate for the learning purpose. Moreover, teachers will be demanded more and more to make use of technological resources, implying that they may also have to adapt their practices to deal with these demands \cite{menezes2019}. A clear picture of the current possibilities available is, thus, a relevant takeaway.

\printbibliography\label{sec-bib}
% if the text is not in Portuguese, it might be necessary to use the code below instead to print the correct ABNT abbreviations [s.n.], [s.l.]
%\begin{portuguese}
%\printbibliography[title={Bibliography}]
%\end{portuguese}


%full list: conceptualization,datacuration,formalanalysis,funding,investigation,methodology,projadm,resources,software,supervision,validation,visualization,writing,review
\begin{contributors}[sec-contributors]
\authorcontribution{Janaina Fernanda de Almeida}[writing,review]
\authorcontribution{William Gottardi}[writing,review]
\authorcontribution{Celso Henrique Soufen Tumolo}[writing,review]
\end{contributors}


\end{document}