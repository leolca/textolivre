% !TEX TS-program = XeLaTeX
% use the following command:
% all document files must be coded in UTF-8
\documentclass[french]{textolivre}
% build HTML with: make4ht -e build.lua -c textolivre.cfg -x -u article "fn-in,svg,pic-align"

\journalname{Texto Livre}
\thevolume{16}
%\thenumber{1} % old template
\theyear{2023}
\receiveddate{\DTMdisplaydate{2023}{1}{29}{-1}} % YYYY MM DD
\accepteddate{\DTMdisplaydate{2023}{3}{28}{-1}}
\publisheddate{\DTMdisplaydate{2023}{5}{23}{-1}}
\corrauthor{Nabil Al-Awawdeh}
\articledoi{10.1590/1983-3652.2023.42796}
%\articleid{NNNN} % if the article ID is not the last 5 numbers of its DOI, provide it using \articleid{} commmand 
% list of available sesscions in the journal: articles, dossier, reports, essays, reviews, interviews, editorial
\articlesessionname{articles}
\runningauthor{Al-Awawdeh} 
%\editorname{Leonardo Araújo} % old template
\sectioneditorname{Daniervelin Pereira}
\layouteditorname{Thaís Coutirnho}

\title{Le contexte universitaire jordanien post-covid et problèmes de l’évaluation en ligne}
\othertitle{O contexto universitário jordaniano pós-covid e os problemas da avaliação \textit{online}}
\othertitle{The post-covid Jordanian university context and problems of online assessment}
% if there is a third language title, add here:
%\othertitle{Artikelvorlage zur Einreichung beim Texto Livre Journal}

\author[1]{Nabil Al-Awawdeh~\orcid{0000-0003-3788-5669}\thanks{Email: \href{mailto:n.awawdeh@yu.edu.jo}{n.awawdeh@yu.edu.jo}}}
\affil[1]{Yarmouk University, Faculty of Arts, Dept. of modern Languages, Irbid, Jordan.}
%A completar

\addbibresource{article.bib}
% use biber instead of bibtex
% $ biber article

% used to create dummy text for the template file
\definecolor{dark-gray}{gray}{0.35} % color used to display dummy texts
\usepackage{lipsum}
\SetLipsumParListSurrounders{\colorlet{oldcolor}{.}\color{dark-gray}}{\color{oldcolor}}

% used here only to provide the XeLaTeX and BibTeX logos
\usepackage{hologo}

% if you use multirows in a table, include the multirow package
\usepackage{multirow}

% provides sidewaysfigure environment
\usepackage{rotating}

% CUSTOM EPIGRAPH - BEGIN 
%%% https://tex.stackexchange.com/questions/193178/specific-epigraph-style
\usepackage{epigraph}
\renewcommand\textflush{flushright}
\makeatletter
\newlength\epitextskip
\pretocmd{\@epitext}{\em}{}{}
\apptocmd{\@epitext}{\em}{}{}
\patchcmd{\epigraph}{\@epitext{#1}\\}{\@epitext{#1}\\[\epitextskip]}{}{}
\makeatother
\setlength\epigraphrule{0pt}
\setlength\epitextskip{0.5ex}
\setlength\epigraphwidth{.7\textwidth}
% CUSTOM EPIGRAPH - END

% LANGUAGE - BEGIN
% ARABIC
% for languages that use special fonts, you must provide the typeface that will be used
% \setotherlanguage{arabic}
% \newfontfamily\arabicfont[Script=Arabic]{Amiri}
% \newfontfamily\arabicfontsf[Script=Arabic]{Amiri}
% \newfontfamily\arabicfonttt[Script=Arabic]{Amiri}
%
% in the article, to add arabic text use: \textlang{arabic}{ ... }
%
% RUSSIAN
% for russian text we also need to define fonts with support for Cyrillic script
% \usepackage{fontspec}
% \setotherlanguage{russian}
% \newfontfamily\cyrillicfont{Times New Roman}
% \newfontfamily\cyrillicfontsf{Times New Roman}[Script=Cyrillic]
% \newfontfamily\cyrillicfonttt{Times New Roman}[Script=Cyrillic]
%
% in the text use \begin{russian} ... \end{russian}
% LANGUAGE - END

% EMOJIS - BEGIN
% to use emoticons in your manuscript
% https://stackoverflow.com/questions/190145/how-to-insert-emoticons-in-latex/57076064
% using font Symbola, which has full support
% the font may be downloaded at:
% https://dn-works.com/ufas/
% add to preamble:
% \newfontfamily\Symbola{Symbola}
% in the text use:
% {\Symbola }
% EMOJIS - END

% LABEL REFERENCE TO DESCRIPTIVE LIST - BEGIN
% reference itens in a descriptive list using their labels instead of numbers
% insert the code below in the preambule:
%\makeatletter
%\let\orgdescriptionlabel\descriptionlabel
%\renewcommand*{\descriptionlabel}[1]{%
%  \let\orglabel\label
%  \let\label\@gobble
%  \phantomsection
%  \edef\@currentlabel{#1\unskip}%
%  \let\label\orglabel
%  \orgdescriptionlabel{#1}%
%}
%\makeatother
%
% in your document, use as illustraded here:
%\begin{description}
%  \item[first\label{itm1}] this is only an example;
%  % ...  add more items
%\end{description}
% LABEL REFERENCE TO DESCRIPTIVE LIST - END


% add line numbers for submission
%\usepackage{lineno}
%\linenumbers

\begin{document}
\maketitle

\begin{polyabstract}
\begin{abstract}
Au cours du processus éducatif à distance, la question qui n’a cessé d’être posée au sein du corps enseignant et qui a inquiété de nombreux étudiants et leurs parents est celle de l'évaluation et de la pertinence des mécanismes d'apprentissage des étudiants. Quelles méthodes peuvent être utilisées pour pallier à l’enseignement en présentiel? Les experts en éducation ont répondu à cette question et ont assuré que plusieurs méthodes et mécanismes existent. Cependant, quelle est leur pertinence et leur efficacité? Les progrès quantitatifs de la technologie n'ont pas suivi les progrès qualitatifs de l'application de cette technologie pour l'évaluation et les tests. L'incapacité des institutions à utiliser correctement cette technologie a entraîné des résultats universitaires pas satisfaisants. Cet article étudie le processus d'évaluation et de test afin d'identifier l'écart entre la théorie et la pratique et de mettre en lumière les faiblesses et les problèmes qui ont impacté le processus d'évaluation et de test. Cette étude est basée sur une enquête dont les résultats sont analysés à l'aide du programme SPSS. L'échantillon de l'étude se compose de 88 enseignants de plusieurs départements de langues vivantes dans des universités jordaniennes ayant travaillé au cours du second semestre de l'année universitaire 2022. Pour construire cet échantillon, nous avons sélectionné au hasard 88 enseignants parmi les 120 qui ont répondu au questionnaire. La méthode analytique descriptive a été choisie pour l'enquête en raison de son applicabilité à la portée globale de l'enquête. Des discussions suivront les résultats pour évaluer la situation où on trouve que les problèmes liés à l'environnement universitaire occupent la première place concernant les problèmes liés à l'utilisation de la technologie par rapport à ceux liés aux enseignants ou aux étudiants, avec une moyenne de 3,99 et un score d'évaluation élevé. 

\keywords{Test d'évaluation \sep Test des étudiants \sep Processus de test \sep E-learning \sep Point de vue des enseignants}

\end{abstract}

\begin{portuguese}
\begin{abstract}
 Durante o processo de educação a distância, a pergunta que não deixou de ser feita dentro do corpo docente e que tem preocupado muitos alunos e seus pais é a da avaliação e a relevância dos mecanismos de aprendizagem do aluno. Que métodos podem ser usados para compensar o ensino presencial? Os especialistas em educação responderam a essa pergunta e garantiram que existem vários métodos e mecanismos. No entanto, qual é a sua relevância e eficácia? Os avanços quantitativos na tecnologia não acompanharam os avanços qualitativos na aplicação dessa tecnologia para avaliação e teste. A incapacidade das instituições de usar adequadamente essa tecnologia resultou em resultados educacionais ruins. Este artigo estuda o processo de avaliação e teste para identificar a lacuna entre a teoria e a prática e para destacar os pontos fracos e os problemas que enfraqueceram o processo de avaliação e teste. Este estudo é baseado em uma pesquisa cujos resultados são analisados usando o programa SPSS. A amostra do estudo é composta por 88 professores de vários departamentos de línguas modernas em universidades jordanianas que trabalharam durante o segundo semestre do ano letivo de 2022. Para construir essa amostra, selecionamos aleatoriamente 88 professores entre os 120 que responderam ao questionário. O método analítico-descritivo foi escolhido para a pesquisa por causa de sua aplicabilidade ao escopo geral da pesquisa. As discussões seguirão os resultados para avaliar a situação em que os problemas relacionados ao ambiente universitário são encontrados em primeiro lugar em termos de problemas relacionados ao uso da tecnologia, em comparação aos relacionados a professores ou alunos, com média de 3,99 e pontuação alta.

\keywords{Teste de nivelamento \sep Teste do aluno \sep Processo de teste \sep E-learning \sep Ponto de vista dos professores}
\end{abstract}
\end{portuguese}

\begin{english}
\begin{abstract}
 During the distance education process, the question that has not ceased to be asked within the faculty and that has worried many students and their parents is the evaluation and relevance of the student's learning mechanisms. What methods can be used to compensate for face-to-face teaching? Education experts answered this question and assured that there are several methods and mechanisms. However, what is its relevance and effectiveness? Quantitative advances in technology have not kept pace with qualitative advances in applying this technology to assessment and testing. Institutions' inability to properly use this technology has resulted in poor educational outcomes. This article studies the assessment and testing process to identify the gap between theory and practice and to highlight weaknesses and problems that have weakened the assessment and testing process. This study is based on a survey whose results are analyzed using the SPSS program. The study sample consists of 88 professors from various departments of modern languages in Jordanian universities who worked during the second semester of the 2022 academic year. To build this sample, we randomly selected 88 professors among the 120 who answered the questionnaire. The descriptive analytical method was chosen for the research because of its applicability to the general scope of the research. Discussions will follow the results to assess the situation where problems related to the university environment are found first in terms of problems related to technology use, compared to those related to teachers or students, with a mean of 3.99 and a high score.

\keywords{Placement test \sep Student test \sep Test process \sep E-learning \sep Teachers' point of view}
\end{abstract}
\end{english}
% if there is another abstract, insert it here using the same scheme
\end{polyabstract}

\section{Introduction}
Dans le contexte des conséquences exceptionnelles que le Coronavirus a eu sur notre quotidien, de nombreux pays, dont la Jordanie, ont pris des mesures de précaution pour maintenir la continuité du processus éducatif, et ce même à distance. La transition entre les examens classiques sur papier et les évaluations en ligne a entraîné une baisse significative des résultats des élèves et des étudiants, et cette baisse s’est encore plus ressentie parmi les élèves les moins bons. Avant même la pandémie, certains pays avaient déjà commencé à expérimenter des évaluations en ligne, une tendance qui devrait se développer rapidement à mesure que les écoles et les universités s'adaptent aux mesures de distanciation sociale. Dans l'Ohio, les écoles offrent de plus en plus souvent aux étudiants la possibilité de passer des examens en ligne. En 2014, 65\% des écoles proposaient des examens en ligne, chiffre qui est monté à 98\% en 2017. Cependant, selon une étude à grande échelle de 2019, les élèves qui ont passé ces examens en ligne avaient des résultats moins bons que leurs pairs qui ont passé des examens sur papier, comme s'ils avaient perdu plusieurs mois d'apprentissage universitaire \cite{daniel_education_2020}. L'étude a également révélé que les enfants issus de familles à faible revenu, les anglophones non natifs et les étudiants handicapés ont été plus durement lésés par les examens en ligne. Ces résultats peuvent perturber de nombreuses écoles qui sont passées aux examens en ligne. La pandémie obligeant les universités à envisager des alternatives au présentiel, beaucoup doivent envisager d’utiliser des évaluations en ligne. Toutefois, les universités doivent tenir compte de l'impact que ce changement peut avoir sur les étudiants, en particulier ceux qui ont le plus de difficultés \cite{giannini2020reopening}.

La digitalisation progressive de l'éducation a donc bénéficié de circonstances favorables, notamment l’obligation de proposer des examens à distance, qui a été fondamentale pour la transformation numérique de l'éducation moderne. Ce terme générique englobe les outils de test, les capacités ou les plateformes d'hébergement en ligne. Les examens en ligne peuvent constituer une alternative fiable, réactive et flexible aux examens traditionnels avec stylo et papier. Les plateformes d’examens en ligne les plus travaillées permettent de tout centraliser au même endroit, de la mise en ligne des questions à la soumission de la copie jusqu’au calcul du résultat final \cite{correl2020evaluacion}.


\section{Revue de la littérature}

Les progrès récents de la technologie offrent un énorme potentiel pour améliorer l'apprentissage des langues. Compte tenu de la façon dont le numérique a changé l’apprentissage des langues, de telles avancées semblent aujourd'hui archaïques. Le concept d'évaluation en ligne est apparu avec l'introduction des premiers ordinateurs dans les années 1970, lorsqu'il a été reconnu que cette nouvelle technologie pouvait offrir de nouvelles possibilités pour la conception et la gestion des examens \cite{cwil2019teacher}. Avec la généralisation d'Internet dans les années 1990, qui a facilité la communication et a permis la démocratisation des examens en ligne comme méthode d'évaluation et de notation des étudiants, les évaluations en ligne ont progressé de manière spectaculaire. Selon \textcite{russell_computer-based_2003}, l’évaluation en ligne n’était pas utilisée dans le domaine de l'éducation avant les années 1980. Cependant, leurs études comparant les examens en ligne avec les examens papier ont commencé à émerger, mettant en lumière les caractéristiques qui affectent la performance des utilisateurs sur les examens en ligne.

L'évaluation en ligne est une évaluation réalisée à l'aide de technologies numériques \cite{eltahir_perspective_2019}. Selon \textcite{akdemir_computer-based_2008}, l'utilisation d’ordinateurs et d'Internet à des fins d'évaluation dans les établissements d'enseignement supérieur s'est développée de manière exponentielle à partir du XXIe siècle. \textcite{nugent2003line} a déclaré que plusieurs pays avaient adopté l'évaluation en ligne à différents stades de l'éducation publique et de l'enseignement supérieur. Par exemple, en 2008, le gouvernement britannique a commencé à utiliser les évaluations en ligne dans l'enseignement public. De nombreuses études ont été menées montrant les nombreux avantages des examens en ligne \cite{nguyen_examining_2017}. Les nouvelles technologies et les circonstances de la pandémie de COVID-19 ont nécessité l'utilisation de nouvelles méthodes d'évaluation modernes, telles que l'évaluation informatisée, l'évaluation en ligne et l'évaluation à distance. Celles-ci sont désormais considérées comme une modalité d’évaluation en pleine évolution dans la plupart des établissements d'enseignement. Cependant, très peu d'études ont tenté d'évaluer les expériences d'évaluation à distance à la lumière de la pandémie de coronavirus. Certaines ont essayé de comprendre l'importance de l'utilisation et de l'emploi de la technologie pour permettre la réalisation des examens pendant la pandémie de coronavirus. \textcite{safil2020} a essayé d’étudier la réalité de l'éducation à distance au sein de l'université algérienne d’Al Arabi! Je pense que c’est incomplet! au cours de la pandémie de coronavirus. Les résultats ont montré que l'impact de la digitalisation sur le processus éducatif était positif sur les cours, les leçons et la communication entre l'enseignant et l’étudiant, mais était négatif en termes de modalités d'évaluation en raison de nombreuses raisons telles que les mauvaises connexions à Internet ou encore la mauvaise qualité des technologies utilisées dans les universités dont dépend l'éducation à distance.

De nombreuses études visent à explorer les applications de l'évaluation en ligne dans les universités et les écoles. Cependant, ces études sont insuffisantes pour conclure, comme l'étude de \textcite{cwil2019teacher} sur l’intérêt et l'efficacité des examens en ligne dans l'enseignement et l'apprentissage comparés aux examens traditionnels. Les résultats de ces études se concentrent sur les perceptions des étudiants et du corps enseignant concernant les avantages, les inconvénients, les défis et l'efficacité de l'évaluation en ligne par rapport aux examens traditionnels. D'autres résultats ont montré que les étudiants ont fait preuve d’adaptabilité et ont accepté l'évaluation en ligne. Ils ont également confirmé qu'ils préfèrent les examens en ligne à type de questionnaires à choix multiples. Un autre avantage des examens en ligne est qu’il est possible pour les étudiants de les refaire plusieurs fois pour améliorer leurs notes \cite{hodgson_effective_2012}. En outre, Macmillan a noté que l'évaluation en ligne n'a pas d'impact négatif sur la réussite des étudiants et que les avantages qu’elle offre sont suffisants et acceptés par les étudiants \cite{spivey_classroom_2014}. En outre, \textcite{wang2016design} affirme que l’évaluation en ligne pourrait réduire la charge de travail des enseignants et renforcer la qualité éducative. Certaines études ont également confirmé que les examens en ligne permettent un retour direct aux étudiants et aident à améliorer l'apprentissage par rapport aux examens traditionnels sur papier \cite{crews_online_2010}. Cependant, l'étude de Betlej montre que les étudiants sont souvent mécontents de l'impossibilité d'expliquer leurs réponses en raison des paramètres stricts de saisie informatique, ce qui a parfois augmenté leur stress et confusion pendant l'examen \cite{betlej2013examinations}. En outre, l'étude de \textcite{gewertz2013} a montré que le fait de rendre des dissertations en ligne et le manque de cohérence de certains examens affectent les résultats académiques. \textcite[p.204]{samlak2021evaluation} voit que les plateformes à distance posent plusieurs problèmes quant à leur fiabilité, validité et faisabilité).


Les examens en ligne ne sont pas à l'abri de la triche, et les contraintes de temps peuvent imposer une charge supplémentaire aux étudiants qui auraient besoin d’aides à l'apprentissage. L'étude de \textcite{da2016attitude} a montré que si l'évaluation en ligne peut être un outil fiable pour mesurer les facteurs axiaux, elle peut également augmenter les niveaux d'anxiété et de stress et faciliter la triche. \textcite{eshet-alkalai_does_2007} ont souligné que les étudiants préfèrent travailler en ligne pendant les études et les examens. Cela peut entraîner une plus grande pression cognitive sur le lecteur. D'autres considèrent les points positifs de l'utilisation de l'évaluation par Internet, tels que la réduction du temps requis pour les examens et la surveillance facile pendant leurs examens \cite{abass2017development}. De plus, certains ont conclu à une relation positive entre la qualité de service et la satisfaction des étudiants \cite{abushamleh2021students}. \textcite{razika2022crise} voit que l’évaluation en ligne représente un enjeu important, non seulement sur le plan du développement personnel et professionnel mais aussi sur le plan économique de temps et d’argent. Pour elle, c’est grâce à la crise du Covid-19 que des approches personnelles et créatives via l’enseignement à distance, peuvent être inventées. Cependant, une revue exhaustive de la littérature a identifié un manque d'études conduites dans les pays du Moyen-Orient pour explorer les points de vue des étudiants sur l'évaluation en ligne.



\section{Méthodologie}

\subsection{Approche de l’étude}
La méthode analytique descriptive a été choisie pour l'enquête en raison de son applicabilité à la portée globale de l'enquête.


\subsection{Échantillon de l'étude}
La population étudiée se compose de 120 enseignants. Nous avons sélectionné au hasard 88 enseignants pour constituer l'échantillon. Le \Cref{tab1} montre la répartition des membres de l'échantillon en fonction des caractéristiques personnelles.

\begin{table}[h!]
\centering
\begin{threeparttable}
\caption{Répartition des membres de l'échantillon en fonction des caractéristiques personnelles (n = 88) }
\label{tab1}
\begin{tabular}{llll}
\toprule
Caractéristiques & Niveau (pourquoi niveau?) & Effectif & Pourcentage \\
\midrule
Genre & Homme & 58 & 65,9\% \\
 & Femme & 30 & 34,1\% \\
 & \textbf{Total} & \textbf{88} & \textbf{100\%} \\
% \midrule
Niveau d’étude & Licence & 51 & 58,0 \\
 & Master & 37 & 42,0 \\
 & \textbf{Total} & \textbf{88} & \textbf{100,0} \\
% \midrule
Années d’expérience & 1-5 	années & 23 & 26,1 \\
 & 6 années et plus & 65 & 73,9 \\
 & \textbf{Total} & \textbf{88} & \textbf{100,0} \\
\bottomrule
\end{tabular}
\source{De l'auteur.}
\end{threeparttable}
\end{table}

Le \Cref{tab1} montre que:
\begin{itemize}
    \item Il y a 58 hommes (65,9\%) et 30 femmes (34,1\%).
    \item 58,0\% des membres de l’échantillon ont un niveau licence et 42,0\% ont un niveau master.
    \item 73,9\% ont plus de 6 années d’expérience et 26,1\% ont entre 1 et 5 années d'expérience.
\end{itemize}
 

\subsection{Outil d'étude}
Un questionnaire a été élaboré pour mener l'étude et obtenir des résultats précis grâce aux statistiques. Il comportait deux sections:

\begin{itemize}
    \item 1- Section 1 : partie du questionnaire sur les variables indépendantes suivantes:
    \begin{itemize}
        \item Le sexe: homme-femme.
        \item La qualification académique: licence et master. 
        \item Les années d'expérience: 1-5 années et 6 années ou plus.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item 2- Deuxième section: partie du questionnaire final composé de 35 items répartis sur trois domaines:
    \begin{itemize}
        \item Les problèmes liés à l'environnement universitaire, composé de 14 items.
        \item Problèmes liés à l'enseignant: 16 items.
        \item Problèmes liés aux étudiants, composé de 5 items.
    \end{itemize}
\end{itemize}

\subsection{Validité de l'outil}
La validité du questionnaire a été vérifiée par plusieurs évaluateurs spécialisés en statistiques. Ils ont fait part de leurs observations et opinions sur la pertinence des items. Ils ont recommandé certaines modifications. Leurs avis, suggestions et observations ont été pris en compte et modifiés à l'unanimité (80\%).

\subsection{Statistique}
Les méthodes statistiques suivantes ont été utilisées:
\begin{itemize}
    \item Les moyennes mathématiques, les écarts types et les rangs ont été utilisés pour répondre à la première question.
    \item Le test t Student a été utilisé pour identifier les différences dans les réponses des membres de l'échantillon en fonction de la variable sexe, du niveau d'éducation et des années d'expérience pour répondre à la deuxième question.
    \item Le coefficient de corrélation de Pearson a été utilisé pour prouver la reproductibilité de l'outil.
    \item Le coefficient alpha de Cronbach a été utilisé pour montrer la cohérence interne des items.
\end{itemize}
  

\subsection{Pertinence de l'outil}
La stabilité de l'outil a été vérifiée en le distribuant à un échantillon de 15 enseignants. Le coefficient de corrélation de Pearson a été calculé. Le coefficient alpha de Cronbach a également été calculé, comme montré dans le \Cref{tab2}.


\begin{table}[h!]
\centering
\begin{threeparttable}
\caption{Coefficient de corrélation par la méthode de Pearson et coefficient alpha de Cronbach.}
\label{tab2}
\begin{tabular}{p{4cm}ll}
\toprule
Domaine d’étude & \multicolumn{1}{p{4cm}}{Coefficient de Cronbach (cohérence interne)} & \multicolumn{1}{p{4cm}}{Coefficient de corrélation de Pearson} \\
\midrule
Problèmes liés à l'environnement universitaire & 0,84 & 0,85* \\
Problèmes liés aux enseignants & 0,88 & 0,82* \\
Problèmes liés aux étudiants & 0,89 & 0,88* \\
Outil dans son ensemble & 0,85 & 0,87* \\
\bottomrule
\end{tabular}%
\notes{* Seuil de signification \(\alpha \geq 0,05\).}
\source{De l'auteur.}
\end{threeparttable}
\end{table}

Il ressort du \Cref{tab2} que: 
\begin{itemize}
\item Les coefficients de cohérence interne Alpha de Cronbach se situent entre 0,89-0,84, ce qui est élevé et acceptable pour les besoins de l’étude. La plupart des études avaient un coefficient de stabilité acceptable à partir de 0,60 \cite{alkilani2012}.
\item Les coefficients de corrélation de Pearson se situent entre 0,82-0,88, qui sont des valeurs significatives. Statistiquement, au seuil de significativité \(\alpha \geq 0,05\) , cela prouve la stabilité de l'outil d'étude.
\end{itemize}
 

\section{Résultats de l'étude}
Cette section comprend une présentation des résultats de l'étude, qui vise à identifier les problèmes de l'utilisation de la technologie dans l'apprentissage en ligne pour évaluer les étudiants de langues vivantes du point de vue de l'enseignant en répondant aux questions de l'étude.

\textbf{Premièrement}: résultats liés à la réponse à la première question: «Quels sont les problèmes rencontrés par les enseignants liés à l'utilisation de la technologie à des fins d'évaluation?».

Pour répondre à cette question, les moyennes mathématiques et les écarts types des réponses des individus ont été calculés. L'étude sur les problèmes liés à l'utilisation de la technologie dans l'enseignement et le \Cref{tab3} l'illustrent.

\begin{table}[h!]
\centering
\begin{threeparttable}
\caption{Moyennes mathématiques et écarts types des réponses concernant les problèmes de l'utilisation de la technologie dans l'apprentissage par ordre décroissant.}
\label{tab3}
\begin{tabular}{lp{4cm}llll}
\toprule
\# & Domaine d’étude & Moyenne & Écart-type & Ordre & Degré \\
\midrule
1 & Problèmes liés à l'environnement universitaire & 3,99 & 0,41 & 1 & Élevé \\
2 & Problèmes liés aux enseignants & 3,52 & 0,50 & 2 & Moyen \\
3 & Problèmes liés aux étudiants & 3,28 & 0,78 & 3 & Moyen \\
\textbf{Total} & & 3,67 & 0,44 & & Moyen \\
\bottomrule
\end{tabular}
\source{De l'auteur.}
\end{threeparttable}
\end{table}

Selon le \cref{tab3}, les moyennes des réponses des membres de l'étude concernant les problèmes liés à l'utilisation de la technologie pour évaluer les élèves se situent entre 3,25-3,99. En première place, se trouve le domaine des «problèmes liés à l'environnement universitaire» avec une moyenne de 3,99, un score d'évaluation élevé. La deuxième place est occupée par les «problèmes liés aux enseignants», avec une moyenne de 3,52 et un score d'évaluation moyen. La troisième place est occupée par les «problèmes liés aux étudiants», avec une moyenne de 3,28 et un score d'évaluation moyen. La moyenne mathématique de l'outil dans son ensemble est de 3,67 avec un degré d'évaluation moyen. Les moyennes et les écarts types des réponses des membres de l'échantillon de l'étude ont été calculés pour les items de chaque domaines séparément, comme le montrent les \Cref{tab4,tab5,tab6}.


\begin{table}[h!]
\centering
\small
\begin{threeparttable}
\caption{Moyenne mathématique, écart-type et ordre des problèmes liés à l'environnement universitaire.
Les universités du point de vue des enseignants de langues vivantes sont classées par ordre décroissant}
\label{tab4}
\begin{tabular}{lp{7.5cm}llll}
\toprule
\# & Item & Moyenne & Écart-type & Ordre & Degré \\
\midrule
1 & Le manque d'outils adaptés dans le département: ordinateur ancien et lent. & 4,27 & 0,81 & 1 & Élevé \\
3 & La déconnexion d'Internet pendant les examens. & 4,18 & 1,06 & 2 & Élevé \\
5 & Le département manque d'intérêt pour la mise à jour des plateformes utilisées pour les évaluations. & 4,17 & 0,79 & 3 & Élevé \\
7 & L'absence d'encouragement des enseignants à utiliser des plateformes différentes de celles proposées par l'université. & 4,13 & 0,93 & 4 & Élevé \\
6 & Le manque de suivi des enseignants pour obtenir un retour sur l'efficacité de l'évaluation en ligne & 4,11 & 0,86 & 5 & Élevé \\
13 & Le manque d'options permettant aux enseignants de changer d'outils d'évaluation. & 4,08 & 0,97 & 6 & Élevé \\
8 & Un nombre considérable d'étudiants sont dans la même classe. & 4,06 & 0,99 & 7 & Élevé \\
4 & Pendant les cours, le temps est compté pour former les élèves à l'utilisation des outils d'évaluation en sachant que les examens de langue sont différents des autres. & 4,01 & 1,00 & 8 & Élevé \\
10 & Les problèmes techniques rendent les examens plus difficiles, car les 	élèves doivent prendre le relais dans de nombreux cas. & 4,01 & 0,92 & 9 & Élevé \\
11 & Le manque de maintenance des ordinateurs avant et pendant les tests. & 3,98 & 0,82 & 10 & Élevé \\
12 & Le manque d'ordinateurs configurés dans la langue apprise par les étudiants qui passent les examens. & 3,91 & 0,84 & 11 & Élevé \\
14 & La quantité considérable de travail des enseignants pendant l'apprentissage en ligne a rendu les examens plus complexes car ils nécessitaient une préparation supplémentaire. & 3,72 & 1,02 & 12 & Élevé \\
2 & Le coût élevé de l'utilisation des technologies dans l'enseignement. & 3,64 & 1,07 & 13 & Moyen \\
9 & Le manque d'options dans les outils et les plateformes fournis pour l'évaluation d'une langue. & 3,56 & 1,04 & 14 & Moyen \\
 & \textbf{Moyenne} & 3,99 & 0,41 & & Élevé \\
\bottomrule
\end{tabular}%
\source{De l'auteur.}
\end{threeparttable}
\end{table}


On constate dans le \Cref{tab4} que les problèmes liés à l'environnement universitaire du point de vue des enseignants sont élevés, puisque la moyenne atteint 3,99 avec un écart type de 0,41. Les résultats des items se situent entre élevés et moyens, puisque les moyennes se situent entre 3,56-4,27. En première position, on retrouve l’item 1 «Le manque d'outils adaptés dans le département: ordinateur ancien et lent» avec une moyenne de 4,27 et un écart type 0,81. En deuxième position, on trouve l’item 3 «La déconnexion d'Internet pendant les examens» avec une moyenne de 4,18 et un écart-type 1,06, avec un degré d'évaluation élevé. L’item 2 «Le coût élevé de l'utilisation des technologies dans l'enseignement» a une moyenne de 3,64 et un écart type 1,07, avec un degré d'évaluation moyen. Le dernier rang est occupé par l’item 9 «Le manque d'options dans les outils et les plateformes fournis pour l'évaluation d'une langue.» avec une moyenne de 3,56, un écart type de 1,04 et un score d'évaluation moyen.


\begin{table}[h!]
\begin{threeparttable}
\centering
\small
\caption{Moyenne mathématique, écart-type et ordre des problèmes liés aux enseignants du point de vue des enseignants de langues vivantes classés par ordre décroissant.}
\label{tab5}
\begin{tabular}{lp{7.5cm}llll}
\# & Item & Moyenne & Écart-type & Ordre & Degré \\
\midrule
1 & Le 	manque de formation et d'orientation des professeurs de langues pour utiliser correctement les plateformes attribuées pour l'évaluation. & 4,40 & 0,69 & 1 & Élevé \\
5 & Tous les ordinateurs et toutes les plateformes sont configurés en anglais uniquement, alors que les examens devraient se faire dans une autre langue. & 4,07 & 0,88 & 2 & Élevé \\
16 & Le manque de connaissances des enseignants pour équilibrer le temps d'évaluation des notions linguistiques. & 4,03 & 0,94 & 3 & Élevé \\
8 & La 	tendance de certains enseignants à simplifier les examens car ils ne sont pas satisfaits de l'évaluation en ligne. & 3,74 & 1,16 & 4 & Élevé \\
13 & Le manque d'intérêt des enseignants à changer leur façon d'enseigner la langue pour s'aligner sur l'évaluation en ligne. & 3,67 & 0,89 & 5 & Moyen \\
12 & L'enseignement en ligne d'une langue minimise les méthodes d'enseignement, ce 	qui rend les tests inadaptés. & 3,65 & 1,12 & 6 & Moyen \\
6 & La 	difficulté d'utiliser la technologie pour enseigner une notion 	linguistique théorique. & 3,63 & 0,93 & 7 & Moyen \\
15 & La difficulté d’organiser l’enseignement en ligne de certains sujets. & 3,55 & 1,10 & 8 & Moyen \\
14 & L'absence 	d'examens en présentiel rend difficile la réduction du niveau de stress des étudiants par l'enseignant & 3,53 & 0,96 & 9 & Moyen \\
2 & La 	conception erronée de l'enseignement et de l'apprentissage en ligne par les professeurs de langues. & 3,51 & 1,19 & 10 & Moyen \\
10 & De nombreux enseignants pensent que les évaluations en ligne ne sont pas fiables et sont une perte de temps. & 3,30 & 1,14 & 11 & Moyen \\
11 & L'impossibilité d'atteindre les objectifs préétablis en évaluant les étudiants en ligne. & 3,30 & 1,08 & 12 & Moyen \\
7 & Les pofesseurs de langues pensent que l'enseignement d'une langue en ligne est inutile et n'est pas comparable au présentiel. & 3,24 & 1,31 & 13 & Moyen \\
3 & L'équité des changements dans l'ère technologique. & 2,93 & 1,17 & 14 & Moyen \\
9 & Les enseignants ont l'impression de ne pas pouvoir surveiller les élèves lorsqu'ils passent les tests. & 2,91 & 1,00 & 15 & Moyen \\
4 & Les enseignants craignent d’abîmer ou d'endommager les outils technologiques fournis par l'université. & 2,81 & 2,81 & 16 & Moyen \\
 & \textbf{Moyenne} & 3,52 & 0,50 & & Moyen \\
\bottomrule
\end{tabular}
\source{De l'auteur.}
\end{threeparttable}
\end{table}

Il ressort du \Cref{tab5} que les problèmes liés aux enseignants sont de niveau moyens, puisque la moyenne est de 3,52 avec un écart-type 0,50, que les items se situent entre élevé et moyen et que leurs moyennes se situent entre 2,81-4,40. L’item 1 «Le manque de formation et d'orientation des professeurs de langues pour utiliser correctement les plateformes attribuées pour l'évaluation» est arrivé en première position avec une moyenne de 4,40, un écart-type de 0,69 et un degré d'évaluation élevé. En deuxième position, on retrouve l’item 5 «Tous les ordinateurs et toutes les plateformes sont configurés en anglais uniquement, alors que les examens devraient se faire dans une autre langue», avec une moyenne de 4,07, un écart-type de 0,88 et un degré d'évaluation élevé. En quinzième position, on retrouve l’item 9 «Les enseignants ont l'impression de ne pas pouvoir surveiller les élèves lorsqu'ils passent les tests», avec une moyenne de 2,91, un écart-type de 1,00 et un degré d'évaluation moyen. En dernière position, on retrouve l’item 4 «Les enseignants craignent d’abîmer ou d'endommager les outils technologiques fournis par l'université», avec une moyenne de 2,81, un écart-type de 1,17 et un score moyen.


\begin{table}[h!]
\centering
\begin{threeparttable}
\centering
\small
\caption{Moyenne, écart-type et ordre des problèmes liés aux étudiants du point de vue des enseignants de langues vivantes classés par ordre décroissant.}
\label{tab6}
\begin{tabular}{lp{7.5cm}llll}
\toprule
\# & Item & Moyenne & Écart-type & Ordre & Degré \\
\midrule
5 & Les étudiants ne sont pas en mesure de résoudre les problèmes techniques qu'ils rencontrent lorsqu'ils passent les tests. & 3,59 & 1,07 & 1 & Moyen \\
2 & L'interaction est limitée pendant les tests, car les élèves ne peuvent pas demander aux enseignants des clarifications ou des explications si nécessaire. & 3,32 & 1,14 & 2 & Moyen \\
3 & Les tests de langue en ligne diminuent l'apprentissage car ils ne mesurent pas toutes les compétences avec précision. & 3,20 & 1,04 & 3 & Moyen \\
4 & L'interaction limitée pendant que les enseignants donnent des cours rend l’évaluation moins pertinente car ils ratent de nombreux détails. & 3,18 & 1,22 & 4 & Moyen \\
1 & Les nseignants ont peur de provoquer les ( tests) pendant les tests. & 3,08 & 1,15 & 5 & Moyen \\
 & \textbf{Moyenne} & 3,28 & 0,78 & & Moyen \\
\bottomrule
\end{tabular}%
\source{De l'auteur.}
\end{threeparttable}
\end{table}

On remarque dans le \Cref{tab6} que les problèmes liés à l'étudiant du point de vue de l'enseignant de langues sont classés comme moyens, puisque la moyenne générale est de 3,28, avec un écart type de 0,78. Tous les items sont également de niveau moyen car les moyennes respectives des items se situent entre 3,08-3,59. L’item 5 «Les étudiants ne sont pas en mesure de résoudre les problèmes techniques qu'ils rencontrent lorsqu'ils passent les tests» arrive en première position, avec une moyenne de 3,59, un écart-type de 1,07 et une note d'évaluation moyenne. En deuxième position, on retrouve l’item 2 «L'interaction est limitée pendant les tests, car les élèves ne peuvent pas demander aux enseignants des clarifications ou des explications si nécessaire», avec une moyenne de 3,32, un écart-type de 1,14, et un degré d'évaluation moyen. En quatrième position se trouve l’item 4 «L'interaction limitée pendant que les enseignants donnent des cours rend l’évaluation moins pertinente car ils ratent de nombreux détails», avec une moyenne de 3,18, avec un écart type de 1,22 et un degré d'évaluation moyen. En dernière position, on retrouve l’item 5 «Les enseignants ont peur de provoquer les élèves pendant les tests» avec une moyenne de 3,08, un écart-type de 1,15 et un degré d'évaluation moyen.

\textbf{Deuxièmement}: Les résultats liés à la deuxième question «Y a-t-il des différences statistiquement significatives (niveau de significativité à 0,05) parmi les membres de l'échantillon de l'étude dans leur estimation des problèmes de leur utilisation de la technologie dans l'évaluation en raison des variables (sexe, qualification éducative, et années d'expérience) ?»

Pour répondre à cette question, le T-Test des échantillons indépendants a été utilisé pour tous les domaines de l'étude et pour l'outil général selon les variables sexe, niveau d'études, années d'expérience, comme le montrent les \Cref{tab7,tab8,tab9}.


\begin{table}[h!]
\centering
\small
\begin{threeparttable}
\caption{Résultats de l'application d'un T-Test d'échantillons indépendants aux domaines de problèmes liés à l'environnement universitaire, aux problèmes liés à l'enseignant et aux problèmes liés aux élèves en fonction de la variable sexe.}
\label{tab7}
\begin{tabular}{p{6cm}lllll}
\toprule
Domaine & Genre & Moyenne & Écart-type & T & \multicolumn{1}{>{\raggedright}p{2.3cm}}{Signification statistique} \\
\midrule
Problèmes liés à l'environnement universitaire & M & 3,97 & 0,38 & 0,61 & 0,54 \\
 & F & 4,02 & 0,46 & & \\
Problèmes liés aux enseignants & M & 3,63 & 0,49 & 3,03 & 0,00* \\
 & F & 3,30 & 0,46 & & \\
Problèmes liés aux étudiants & M & 3,30 & 0,76 & 0,42 & 0,68 \\
 & F & 3,23 & 0,81 & & \\
Outil dans son ensemble & M & 3,72 & 0,43 & 1,40 & 0,16 \\
 & F & 3,58 & 0,46 & & \\
\bottomrule
\end{tabular}%
\notes{* Seuil de signification \(\alpha \geq 0,05\).}
\source{De l'auteur}
\end{threeparttable}
\end{table}




Dans le \Cref{tab7}, on remarque que:
\begin{itemize}
    \item Il existe des différences statistiquement significatives à 0,052 entre les opinions des membres de l'échantillon sur le domaine des problèmes liés aux enseignants en fonction de la variable sexe, où la valeur T est statistiquement significative à 3,03, en faveur des hommes, avec une moyenne de 3,63. En revanche, la moyenne pour les femmes est à 3,30.
    \item Il n'y a pas de différence statistiquement significative à 0,052 entre les opinions des membres de l'échantillon sur les deux domaines des problèmes liés à l'environnement universitaire  et des problèmes liés aux élèves selon la variable du sexe, où les valeurs ne sont pas statistiquement significatives.
    \item  Il n'y a pas de différence statistiquement significative à 0,052 entre les opinions des membres de l'échantillon sur l'outil dans son ensemble selon la variable du genre, où la valeur T à 1,40 est non statistiquement significative.
\end{itemize}



\begin{table}[h!]
\centering
\small
\begin{threeparttable}
\caption{Résultats de l'application du T-Test des échantillons indépendants aux problèmes liés à l'environnement d'étude, aux problèmes liés aux enseignants et aux problèmes liés aux étudiants en fonction de la variable du niveau d’étude.}
\label{tab8}
\begin{tabular}{p{5cm}lllll}
\toprule
Domaines & \multicolumn{1}{>{\raggedright}p{1.5cm}}{Niveau d’étude} & Moyenne & Écart-type & T & \multicolumn{1}{>{\raggedright}p{2.5cm}}{Signification statistique} \\
\midrule
Problèmes liés à l'environnement universitaire & Licence & 3,99 & 0,35 & 0,16 & 0,04* \\
& Master & 3,98 & 0,48 & & \\
Problèmes liés aux enseignants & Licence & 3,51 & 0,54 & 0,21 & 0,26 \\
& Master & 3,53 & 0,45 & & \\
Problèmes liés aux étudiants & Licence & 3,22 & 0,84 & 0,78 & 0,12 \\
& Master & 3,35 & 0,68 & & \\
Outil dans son ensemble & Licence & 3,66 & 0,46 & 0,25 & 0,52 \\
& Master & 3,68 & 0,42 & & \\
\bottomrule
\end{tabular}%
\notes{* Seuil de signification \(\alpha \geq 0,05\).}
\source{De l'auteur}
\end{threeparttable}
\end{table}


Dans le \Cref{tab8}, on remarque que:
\begin{itemize}
    \item Il existe des différences statistiquement significatives à 0,052 entre les opinions des membres de l'échantillon sur le domaine des problèmes liés à l'environnement universitaire selon la variable du niveau d’étude, où la valeur T à 0,16 est statistiquement significative, en faveur de la licence avec une moyenne de 3,99. La moyenne dans le niveau d’étude master est à 3,98.
    \item Il n'y a pas de différences statistiquement significatives à 0,052 entre les opinions des membres de l'échantillon sur les deux domaines des problèmes liés aux enseignants et les problèmes liés aux élèves selon la variable du niveau d’étude, car les valeurs T ne sont pas statistiquement significatives.
    \item Il n'y a pas de différence statistiquement significative à 0,052 entre les opinions des membres de l'échantillon sur l'outil dans son ensemble car la valeur T à 0,25 n'est pas statistiquement significative.
\end{itemize}


\begin{table}[h!]
\centering
\small
\begin{threeparttable}
\caption{Résultats de l'application du T-Test des échantillons indépendants aux problèmes liés à l'environnement d'étude, aux problèmes liés aux enseignants et aux problèmes liés aux étudiants en fonction de la variable des années d'expérience.}
\label{tab9}
\begin{tabular}{p{4.5cm}lllll}
\toprule
Domaine & Années d’expérience & Moyenne & Écart-type & T & \multicolumn{1}{>{\raggedright}p{1.8cm}}{Signification statistique} \\
\midrule
Problèmes liés à l'environnement universitaire & 1-5 & 3,90 & 0,35 & -1,19 & 0,52 \\
 & 6 années et plus & 4,02 & 0,42 & & \\
Problèmes liés aux enseignants & 1-5 & 3,25 & 0,48 & -3,09 & 0,54 \\
 & 6 années et plus & 3,61 & 0,48 & & \\
Problèmes liés aux étudiants & 1-5 & 2,70 & 0,55 & -4,63 & 0,03* \\
 & 6 années et plus & 3,48 & 0,74 & & \\
Outil dans son ensemble & 1-5 & 3,43 & 0,39 & -3,19 & 0,51 \\
 & 6 années et plus & 3,75 & 0,43 & & \\
\bottomrule
\end{tabular}%
\notes{* Seuil de signification \(\alpha \geq 0,05\).}
\source{De l'auteur}
\end{threeparttable}
\end{table}


Dans le \Cref{tab9}, on remarque que:

\begin{itemize}
    \item Il existe des différences statistiquement significatives à 0,052 entre les opinions des membres de l'échantillon sur le domaine des problèmes liés aux étudiant selon la variable années d'expérience, où la valeur T a atteint -4,63. C'est une valeur statistiquement significative en faveur des années d'expérience 6 années ou plus avec une moyenne de 3,48, alors que la moyenne pour les années d'expérience entre 1-5 années était de 2,70.
    \item Il n'y a pas de différence statistiquement significative à 0,052 entre les opinions des membres de l'échantillon sur les deux domaines de problèmes liés aux enseignants et les  problèmes liés aux études, selon la variable années d'expérience, où les valeurs T ne sont pas statistiquement significatives.
    \item Il n'y a pas de différences statistiquement significatives au niveau de signification $\alpha \leq 13,1$ entre les opinions des membres de l'échantillon sur l'outil dans son ensemble, selon la variable années d'expérience, où la valeur T était de -3,19, non statistiquement significative.
\end{itemize}


\section{Discussion des résultats}
Cette section comprend une présentation des résultats de l'étude, qui vise à identifier les problèmes d'utilisation de la technologie dans l'évaluation et les examens auxquels sont confrontés les enseignants de langues vivantes en Jordanie, de leur point de vue, à travers les réponses aux questions de l'étude.

\textbf{Premièrement} : discussion sur les résultats liés à la réponse à la première question: «Quels sont les problèmes rencontrés par les enseignants liés à l'utilisation de la technologie à des fins d'évaluation?». Les résultats ont montré que les moyennes des réponses sur les problèmes d'utilisation de la technologie dans l'évaluation et les tests se situaient entre 3,28-3,99. Au premier rang vient le domaine des problèmes liés à l'environnement universitaire, avec une moyenne de 3,99 et un score d'évaluation élevé. Au deuxième rang se trouve le domaine des problèmes liés aux enseignants, avec une moyenne de 3,22 et un score d'évaluation moyen. Au troisième rang vient le domaine des problèmes liés aux étudiants avec une moyenne de 3,28 et un score moyen. La moyenne de l'outil dans son ensemble est de 3,67 avec un score d'évaluation moyen. Ceci est dû au manque de ressources financières de l'université. L'université dépend des dons et d’allocations financières du ministère de l'Enseignement supérieur, ce qui ne permet pas à l'administration de fournir des technologies modernes, comme le montrent les résultats aux questions portant sur les ordinateurs portables pour les enseignants et les étudiants. Nous pouvons expliquer ces résultats par la culture dominante dans la communauté éducative sur la spécialisation des langues et l'absence de besoin de moyens et de méthodes pour la soutenir. Par conséquent, le ministère de l'Enseignement supérieur ne semble pas vouloir fournir un soutien suffisant pour l'utilisation de la technologie dans l'enseignement des langues modernes. Nous pouvons également attribuer ces résultats au fait que la plupart des stratégies éducatives utilisées dans les universités se concentrent sur la méthode traditionnelle d'enseignement des langues, qui ne dépend pas de la technologie moderne.

Ainsi, nous pouvons expliquer ces résultats par les capacités limitées de l'université à fournir et encourager le développement de la technologie. L'administration devrait posséder des capacités matérielles spécifiques pour valoriser l'utilisation et le développement de la technologie. Nous pouvons donc attribuer ce résultat au fait que les capacités de l'université en Jordanie concernant les équipements en ordinateurs et des laboratoires et l'impact des autres équipements connexes dans le développement de la technologie sont limitées. Cela peut s'expliquer par le fait que la plupart des professeurs de langues ne sont peut-être pas assez qualifiés pour utiliser la technologie dans l'enseignement et qu'ils ne le souhaitent pas. Ceci peut être dû au manque d'équipement qui limite le rôle de l'enseignant dans le développement de l'utilisation de la technologie dans l'enseignement des matières linguistiques. Nous pouvons penser que ce résultat est lié au fait que l’utilisation de la technologie dans l'éducation dépend souvent d'Internet, ce qui limite son utilisation dans les foyers en raison des déconnexions fréquentes dans le contexte de la situation actuelle et de la forte pression sur le réseau. Le chercheur attribue également ce résultat à l'inadéquation des salles de classe. Nous pouvons également expliquer ces résultats par l'inadéquation des plateformes et des équipements pour une utilisation efficace de la technologie et de ses activités pédagogiques. La majorité des salles de classe sont des salles standard qui ne disposent pas de l'équipement nécessaire à l'utilisation de la technologie.

Le domaine des problèmes liés aux étudiants est arrivé en dernière position, mais avec une note moyenne, ce qui signifie que certains des problèmes liés à l'utilisation de la technologie concernent les étudiants mais qu'ils sont classés en dernière position du point de vue de leurs enseignants. Ce résultat sont cohérents avec ceux de l'étude \textcite{alomari2011}, qui a montré que les obstacles auxquels est confrontée l'application réelle des programmes de langues informatisés liés à l'université sont au premier rang, ceux liés aux enseignant arrivent en deuxième position avec un degré d'obstacle moyen et ceux liés aux étudiants arrivent en troisième position, avec un degré moyen. L'étude \textcite{alnuaimi2011} a également montré que les obstacles liés à l'organisation de l'enseignant étaient les plus influents dans la réticence des enseignants de langue à utiliser les méthodes d'enseignement modernes.

En ce qui concerne le domaine des problèmes liés à l'environnement universitaire, les résultats ont montré que ces problèmes sont importants du point de vue des professeurs de langues, car les moyennes des réponses pour les items de ce domaine se situent entre 3,56-4,27. Au premier rang se trouve l’item 1 «Le manque d'outils adaptés dans le département: ordinateur ancien et lent» avec un degré d'évaluation élevé. L’item 9 «Le manque d'options dans les outils et les plateformes fournis pour l'évaluation d'une langue» arrive en dernière position avec un degré d'évaluation moyen. Ce résultat peut s'expliquer par la tendance de l'environnement éducatif en Jordanie à suivre la méthode traditionnelle consistant à apporter des informations et connaissances aux étudiants sans leur fournir de compétences supplémentaires ni les aider dans leur créativité et l'accès à l'information. Par conséquent, les responsables éducatifs sont peu conscients de l'importance d'employer et d'investir dans la technologie pour améliorer l'efficacité de l’enseignement par la planification et la mise en œuvre de moyens technologiques afin que l’énergie des étudiants soit investie de manière positive et productive. Les résultats ont montré que les problèmes liés aux professeurs de langue étaient modérés, car les moyennes se situaient entre 2,81-4,40 et venaient au premier rang, l’item 1 «Le manque de formation et d'orientation des professeurs de langues pour utiliser correctement les plateformes attribuées pour l'évaluation» avec une moyenne de 4,40 avec un écart type de 0,69 et un degré d'évaluation élevé. L’item 4 «Les enseignants craignent d’abîmer ou d'endommager les outils technologiques fournis par l'université» arrive au dernier rang avec une moyenne de 2,81, un écart-type de 1,17 et un degré d'évaluation moyen.

Les résultats ont montré que les problèmes liés aux enseignants étaient modérés, avec des moyennes comprises entre 2,81-4,40. Au premier rang, on retrouve l’item 1 «Le manque de formation et d'orientation des professeurs de langues pour utiliser correctement les plateformes attribuées pour l'évaluation» avec une moyenne de 4,40 avec un écart type de 0,69 et un degré d'évaluation élevé. L’item 4 «Les enseignants craignent d’abîmer ou d'endommager les outils technologiques fournis par l'université» arrive au dernier rang avec une moyenne de 2,81, un écart-type de 1,17 et un degré d'évaluation moyen. Nous pouvons attribuer ce résultat à la méconnaissance de l'importance de l'utilisation de la technologie comme complément au programme d'enseignement. En outre, elle prévoit la formation d'une personnalité intégrée et équilibrée de l'élève par le développement de certaines compétences liées à la recherche, à la conclusion et à l'analyse, ce qui empêche l'enseignant de renforcer la capacité à l'utiliser. Ce résultat diffère de l'étude de \textcite{hou2004important}, qui a conclu que les enseignants possèdent des compétences cognitives de 80\%. L'étude \textcite{ahmed2007} a révélé que le matériel et les appareils éducatifs étaient disponibles dans des proportions variables selon les écoles. L'étude de \textcite{deborahlliza2007} a conclu qu'il existe une interaction et un intérêt élevé entre les enseignants et les enseignantes pour l'utilisation des ordinateurs dans le travail administratif et la recherche de sources. En revanche, dans le processus d'enseignement, l'ordinateur est utilisé comme un outil de soutien pour l'enseignant et non comme une stratégie d'enseignement.

Du point de vue des professeurs de langues, les résultats relatifs aux étudiants sont moyens. Les moyennes se situent entre 3,59-3,08. En première position, on retrouve l’item 5 «Les étudiants ne sont pas en mesure de résoudre les problèmes techniques qu'ils rencontrent lorsqu'ils passent les tests» avec une moyenne de 3,59, un écart-type de 1,07 et un degré d'évaluation élevé. Au dernier rang, on retrouve l’item 1 «Les enseignants ont peur de provoquer les élèves pendant les tests» , avec une moyenne de 3,08, un écart-type de 1,15 et un degré d'évaluation moyen. Nous pouvons attribuer ce résultat à l'incapacité de l'université à fournir l'équipement nécessaire à chaque étudiant. Les étudiants préfèrent faire d'autres choses plutôt que s’intéresser à des programmes informatiques. De plus, nous pouvons aussi souligner la faiblesse des étudiants dans la langue anglaise et celle des enseignants eux-mêmes qui ne connaissent pas bien le langage technique, surtout en anglais, langue dans laquelle sont configurés tous les ordinateurs. Ce résultat diffère de l'étude de \textcite{hou2004important} qui concluait que le domaine de l'intérêt et de la motivation des élèves était le premier en termes d’importance. Cette différence peut être justifiée par la différence entre la population de la présente étude et son échantillon d'étude \cite{hou2004important}.

\textbf{Deuxièmement} : discussion sur les résultats liés à la deuxième question «Y a-t-il des différences statistiquement significatives (niveau de significativité à 0,05) parmi les membres de l'échantillon de l'étude dans leur estimation des problèmes de leur utilisation de la technologie dans l'évaluation en raison des variables (sexe, qualification éducative, et années d'expérience)?»

Les résultats ont montré qu'il y avait des différences statistiquement significatives entre les opinions des membres de l'échantillon sur le domaine des problèmes liés aux enseignants en fonction de la variable du sexe, en faveur des hommes avec une moyenne de 3,63, alors que la moyenne des femmes était de 3,30. Ceci indique que les enseignants masculins font face à plus de problèmes dans l'utilisation de la technologie que leurs homologues féminines. Par ailleurs, les résultats n'ont pas montré de différence statistiquement significative entre les opinions sur les deux domaines des problèmes liés à l'environnement universitaire et des problèmes liés aux élèves en fonction de la variable sexe. Ces résultats peuvent s'expliquer par le fait que les enseignantes sont plus susceptibles d'utiliser la technologie et sont plus enclines à l'utiliser de par leur nature, car elles la voient d'un œil plus positif que leurs homologues masculins. En effet, via la technologie, les enseignants peuvent effectuer certaines tâches professionnelles à domicile, ce qui peut les inciter à se former. Ce résultat peut être dû au fait que les enseignantes sont conscientes de l'importance de ces méthodes et à un degré plus élevé que leurs collègues masculins. Ce résultat est en accord avec l'étude \textcite{alomari2011}, qui a montré des différences statistiquement significatives dans les estimations des membres de l'échantillon en fonction du sexe et en faveur des enseignantes.

Concernant la variable du niveau d’éducation, les résultats ont montré qu'il y avait des différences statistiquement significatives entre les opinions des membres de l'échantillon sur les problèmes liés à l'environnement universitaire en faveur du niveau Licence avec une moyenne de 3,99. En revanche, la moyenne pour le niveau Master était de 3,98, ce qui indique que les enseignants titulaires d'une licence rencontrent plus de problèmes liés à l'utilisation de la technologie que ceux qui ont des diplômes plus élevés. Les résultats n'ont montré aucune différence statistiquement significative entre les opinions des membres de l'échantillon sur les deux domaines d'études des problèmes liés aux enseignants et aux étudiants selon la variable du niveau d’éducation. Nous pouvons attribuer ce résultat au fait que les enseignants qui ont des niveaux plus élevés peuvent mieux évaluer les éléments de l'environnement éducatif que les autres, à la lumière du développement technologique et de la révolution de l'information. L'avenir du processus éducatif et l'utilisation de la technologie dans l'évaluation est l'un des éléments de cette vision. Ils doivent choisir ce qui leur convient parmi les différentes méthodes d'enseignement. Ce résultat diffère de l'étude \textcite{ahmed2007}, qui a conclu qu'il n'y avait pas de différences statistiquement significatives \(\alpha \geq 0,05\) dans l'étendue des technologies éducatives en raison du sexe et de la qualification éducative.

En ce qui concerne la variable années d'expérience, les résultats ont montré qu'il y avait des différences statistiquement significatives entre les opinions des membres de l'échantillon sur le domaine des problèmes liés aux étudiants, en faveur des années d'expérience 6 années et plus avec une moyenne de 3,48, tandis que la moyenne des années d'expérience 1-5 ans a atteint 2,70, ce qui indique de manière surprenante que les enseignants ayant plus d'expérience font face à plus de problèmes d'utilisation de la technologie que les autres. Les résultats ont également montré qu'il n'y avait pas de différences statistiquement significatives entre les opinions des membres de l'échantillon sur les deux domaines des problèmes liés aux enseignants et les problèmes liés aux étudiants, car les valeurs T n'étaient pas statistiquement significatives. Ces résultats peuvent être expliqués par le fait que les enseignants ayant moins d'expérience ont pu avoir accès à des cours de formation sur l'utilisation de la technologie plus que les autres, que ce soit par des cours du ministère de l'Enseignement supérieur, ou par la formation aux propres frais de l'enseignant. Cela peut être aussi dû à la sensibilisation des nouveaux enseignants à l'importance de la technologie. Ce résultat est en accord avec l'étude \textcite{ahmed2007}, qui a conclu qu'il y avait des différences statistiquement significatives dues à l'expérience et en faveur de ceux qui ont de l'expérience (6 années ou plus).


\section{Conclusion}

En raison de la pandémie de coronavirus, la plupart des établissements d'enseignement, tels que les universités, ont dû utiliser la technologie dans l'enseignement, y compris pour évaluer leurs étudiants en ligne. L'étude actuelle a cherché à enquêter sur les résultats de l'évaluation en ligne des étudiants dans les universités jordaniennes et à examiner les lacunes éducatives et les théories pour les développer et les améliorer depuis la pandémie de COVID-19. L'opinion des enseignants a été étudiée et analysée en détail. Leur impression peut être due aux inconvénients associés à l'évaluation en ligne et à la possibilité pour les étudiant de passer leurs examens n'importe où et n'importe quand. Sur la base des résultats de l'étude, on peut conclure que le fait de fournir aux enseignants les outils technologiques appropriés leur permettra de mener à bien le processus d'évaluation tout en maintenant le système éducatif et en limitant son interruption. Il est également important que les universités préparent des programmes de formation pour les enseignants pour les former à l'utilisation de la technologie dans l'évaluation.

En outre, l'étude révèle la nécessité de passer de l'enseignement traditionnel à l'enseignement à distance, en connectant tous les établissements d'enseignement à des réseaux d'information modernes et en soulignant la nécessité pour le gouvernement d’investir et de former les enseignants à l'utilisation de la technologie dans l'enseignement. L'étude recommande également de sensibiliser tout l'environnement éducatif aux objectifs et aux capacités de l'utilisation de la technologie dans l'évaluation, en particulier dans le département des langues modernes. Les croyances selon lesquelles les tests en lignes sont impossibles doivent changer. Il faut également donner aux étudiants des compétences supplémentaires et favoriser leur confiance pour qu’ils se familiarisent avec l'e-testing.


\printbibliography\label{sec-bib}
% if the text is not in Portuguese, it might be necessary to use the code below instead to print the correct ABNT abbreviations [s.n.], [s.l.]
%\begin{portuguese}
%\printbibliography[title={Bibliography}]
%\end{portuguese}



\end{document}

