\section{Resultados}\label{sec-resultados}
\subsection{Jueceo de ítems diseñados por Humanos y ChatGPT}

Como se mencionó anteriormente, en este estudio se contemplaron dos
etapas. En este segmento se compara el resultado del jueceo según los
ítems diseñados por humanos y ChatGPT. Por un lado, se le solicitó a
ChatGPT \cite{OpenAI2023} que elaborara 24 ítems, de forma separada, pero
siguiendo los criterios marcados, y por otro, se le solicitó a cuatro
diseñadores elaborar un total de 56 ítems, 14 por cada uno de ellos. Con
el fin de evaluarlos se sometió a una revisión a doble ciego con dos
jueces humanos y un tercer juez que fue el propio ChatGPT, pero con los
parámetros de la rúbrica.

Como se describió en la metodología, se procedió a organizar la base de
datos y realizar la prueba chi-cuadrado. En la \Cref{tab-02} se pueden
observar los resultados de este primer análisis, no se observa una
diferencia significativa entre cómo evaluaron los jueces los ítems
desarrollados por humanos o por ChatGPT (Juez A, p = .758; Juez B (
.264); ChatGPT, p = 1.0). No obstante, este último, ChatGPT, muestra una
respuesta rotunda (p=1), por lo que habrá que tener cuidado sobre un
comportamiento repetitivo más que crítico.

\begin{table}[htbp]
\centering
\caption{Resultados chi-cuadrado entre ítems diseñados por humanos y
 ChatGPT según la visión de los jueces.}
\label{tab-02}
\begin{tabular}{llllp{5cm}}
\toprule
Creador & \multicolumn{1}{>{\raggedright}p{2cm}}{Chi-cuadrado de Pearson} & \multicolumn{1}{>{\raggedright}p{2cm}}{Grados de Libertad (gl)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Significación Asintótica (Bilateral)} & Notas \\
\midrule
Juez\_A & 1.179 & 3 & .758 & 3 casillas (37.5~\%) tuvieron un
recuento esperado menor que 5. El recuento mínimo esperado fue .67. \\
Juez\_B & 1.247 & 1 & .264 & 2 casillas (50.0~\%) tuvieron un
recuento esperado menor que 5. El recuento mínimo esperado fue 2.33.
Solo para una tabla 2x2. \\
ChatGPT & .000 & 2 & 1.000 & 4 casillas (66.7~\%) tuvieron un
recuento esperado menor que 5. El recuento mínimo esperado fue 1.00. \\ 
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

Para complementar y teniendo los mismos resultados, se realizó la prueba
Kruskal-Wallis \cite{Field2013,Howell2012}, debido a que los resultados
de la prueba de normalidad fueron: no normal. Los resultados de la
prueba Kruskal-Wallis se observa en la \Cref{tab-03}, con los cuales se puede
confirmar que no hay diferencias significativas en las evaluaciones
(Juez\_A, Juez\_B, ChatGPT) entre los ítems creados por humanos y los
generados por ChatGPT, recordando que un valor \emph{p} menor que el
nivel de significancia elegido (0.05) indica que hay diferencias
estadísticamente significativas entre los grupos. Por ejemplo, los
resultados de Juez\_A y ChatGPT, donde los valores \emph{p} son 0.787 y
1.000 respectivamente, lo que sugiere que no hay diferencias
significativas en las evaluaciones entre los diferentes creadores de
ítems; estos resultados son similares a la realizada con chi-cuadrado
Mann Withney.

\begin{table}[htbp]
\centering
\caption{Resultados de la prueba Kruskal Wallis entre las evaluaciones de
los jueces sobre los ítems realizados entre humanos y ChatGPT.}
\label{tab-03}
\begin{tabular}{llllll}
\toprule
Variable & \multicolumn{1}{>{\raggedright}p{2cm}}{H de Kruskal-Wallis} & \multicolumn{1}{>{\raggedright}p{2cm}}{Grados de Libertad (gl)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Significación Asintótica (p-valor)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Prueba de la Mediana - Chi-cuadrado} & \multicolumn{1}{>{\raggedright}p{2cm}}{Prueba de la Mediana - Sig. Asintótica} \\
\midrule
Juez\_A & 0.073 & 1 & 0.787 & 0.386 & 0.534 \\
Juez\_B & 1.232 & 1 & 0.267 & 1.247 & 0.264 \\
ChatGPT & 0.000 & 1 & 1.000 & 0.000 & 1.000 \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

Por otro lado, se analizaron los resultados por comparación de medias,
donde se puede decir, con reservas, que los resultados del jueceo,
únicamente realizado por humanos (Juez A y B), revelan diferencias
sutiles en la aceptación de ítems entre los creados por ChatGPT y los
diseñadores humanos. En la \Cref{tab-04}, los ítems de ChatGPT mostraron una
tasa de aceptación sin cambios ligeramente superior (67.85~\%) en
comparación con los diseñadores humanos (65.17~\%). Esto sugiere que, en
términos de cumplir con los criterios establecidos inicialmente, según
los contenidos sobre Lengua Escrita, los ítems generados por ChatGPT (A
y D) se alinearon ligeramente mejor con las expectativas de los jueces.
Sin embargo, es notable que los ítems humanos (B, C, E y F) tuvieron una
tasa menor de cambios menores requeridos, pero una tasa más alta de
cambios mayores necesarios. Esto podría indicar que mientras los ítems
de ChatGPT generalmente se acercaban más a las expectativas iniciales,
los ítems humanos, cuando requerían modificaciones, necesitaban ajustes
más sustanciales.

\begin{table}[htbp]
\centering
\caption{Aceptación y comparación entre ítems realizados por humanos vs
ChatGPT (Juez A y B).}
\label{tab-04}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{>{\raggedright}p{2cm}}{Diseñadores (14 ítems por c/u)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Sin Cambios (Promedio)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Menores (Promedio)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Mayores (Promedio)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Rechazados (Promedio)} \\
\midrule
%ChatGPT (A y D) & 0.6785 \textbar{} 67.8 5\% & 0.125 \textbar{} 12.5~\% & 0.1785 \textbar{} 17.85~\% & 0.0178 \textbar{} 1.7~\% \\
%Humanos (B, C, E, F) & 0.6517 \textbar{} 65.17~\% & .0625 \textbar{} 6.25~\% & .2767 \textbar{} 27.67~\% & 0.0089 \textbar{} 0.89 \% \\
ChatGPT (A y D) & 67.8 5\% & 12.5~\% & 17.85~\% & 1.7~\% \\
Humanos (B, C, E, F) & 65.17~\% & 6.25~\% & 27.67~\% & 0.89~\% \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

En la \Cref{tab-05}, que incluye la evaluación del Juez C (ChatGPT 4.0), se
observa un aumento en la tasa de aceptación sin cambios para ambos
grupos, siendo ligeramente más pronunciado para los ítems de ChatGPT (A
y B). Este aumento podría reflejar una alineación en la forma de evaluar
entre el ChatGPT como diseñador y como juez. Sin embargo, la tasa de
aceptación sin cambios también aumentó para los ítems humanos cuando
ChatGPT actuó como juez, lo que sugiere una evaluación consistente y
objetiva por parte de la IA. La disminución en la necesidad de cambios
menores y mayores para ambos grupos implica que el Juez C (ChatGPT) tuvo
una tendencia general a requerir menos modificaciones en los ítems.

\begin{table}[htbp]
\centering
\caption{Aceptación y comparación entre ítems realizados por humanos vs ChatGPT (Juez A, B y C).}
\label{tab-05}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{>{\raggedright}p{2cm}}{Grupo de Diseñadores} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Sin Cambios (Promedio)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Menores (Promedio)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Mayores (Promedio)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Rechazados (Promedio)} \\
\midrule
%ChatGPT (A y D) & 0.7619 \textbar{} 76.19~\% & 0.0952 \textbar{} 9.52~\% & 0.1309 \textbar{} 13.9~\% & 0.0119 \textbar{} 1.19~\% \\
%Humanos (B, C, E, F) & 0.7440 \textbar{} 74.40~\% & 0.0535 \textbar{} 5.35~\% & 0.1964 \textbar{} 19.64~\% & 0.0059 \textbar{} 0.59~\% \\
ChatGPT (A y D) & 76.19~\% & 9.52~\% & 13.9~\% & 1.19~\% \\
Humanos (B, C, E, F) & 74.40~\% & 5.35~\% & 19.64~\% & 0.59~\% \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

No obstante, cuando se observan los resultados por diseñador, sin jueces
específicos y a partir de medias, se encuentra que no hay grandes
diferencias entre los resultados de cada uno de los diseñadores. Según
la \Cref{tab-06}, que refleja el promedio de decisiones tomadas por los tres
jueces (Juez A, Juez B y Juez C - ChatGPT 4), el 75~\% de los ítems de
todos los diseñadores fueron aceptados sin cambios, lo que indica una
alta calidad general y una alineación efectiva con los estándares de
evaluación. Este alto porcentaje de aceptación sin cambios sugiere que
la mayoría de los ítems fueron considerados adecuados y pertinentes
desde su presentación inicial. Sin embargo, hay variabilidad entre los
diseñadores, con el Diseñador B alcanzando la tasa más alta de
aceptación sin cambios (83.33~\%) y el Diseñador F la más baja (66.67
\%). Esta variación puede reflejar diferencias en los enfoques de diseño
de ítems o en la interpretación de los criterios de evaluación.

\begin{table}[!htpb]
\centering
\caption{Control de aceptación de ítems (promedio).}
\label{tab-06}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{>{\raggedright}p{2cm}}{Diseñador} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Sin Cambios (\%)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Con Cambios Menores (\%)} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Con	Cambios Mayores (\%)} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Rechazado (\%)} \\
\midrule
A & 78.57~\% & 14.29~\% & 7.14~\% & 0.00~\% \\
B & 83.33~\% & 9.52~\% & 7.14~\% & 0.00~\% \\
C & 73.81~\% & 4.76~\% & 19.05~\% & 2.38~\% \\
D & 73.81~\% & 4.76~\% & 19.05~\% & 2.38~\% \\
E & 73.81~\% & 4.76~\% & 21.43~\% & 0.00~\% \\
F & 66.67~\% & 2.38~\% & 30.95~\% & 0.00~\% \\
Media & 75~\% & 6.75~\% & 17.46~\% & 0.79~\% \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}


En cuanto a los ítems que requirieron cambios menores, la media se sitúa
en un 6.75~\%. Este porcentaje relativamente bajo indica que solo una
fracción menor de los ítems necesitaba ajustes leves para cumplir con
los criterios de evaluación. Nuevamente, existe una variación entre los
diseñadores, siendo el Diseñador B el que más a menudo requirió estos
ajustes. Los ítems que necesitaron cambios mayores presentaron una media
del 17.46~\%, lo que sugiere que, aunque en menor medida que los
aceptados sin cambios, una proporción considerable de ítems necesitó
modificaciones más sustanciales. En cuanto a la tasa de rechazo, esta
fue bastante baja, con una media del 0.79~\%, solo los Diseñadores C y D
experimentaron rechazos, aunque en una proporción mínima, lo que indica
que la gran mayoría de los ítems fueron considerados válidos y adecuados
en cierta medida.


\subsection{Consistencia y resultados entre jueces}
Sin duda, a pesar de que hubo una rúbrica como guía, como se observa en
la \Cref{tab-07}, hubo diferencias significativas entre las evaluaciones del
Juez A, B y C. El Juez A mostró un enfoque más crítico en la evaluación,
con solo un 39.29~\% de ítems aceptados sin cambios. Esta tasa más baja
sugiere un estándar riguroso o criterios más estrictos en la evaluación.
Además, un 16.67~\% de los ítems necesitó cambios menores, y una
proporción significativa, 41.67~\%, requirió cambios mayores. También se
observó un pequeño porcentaje de rechazo (2.38~\%), lo que indica que
algunos ítems no cumplían con los estándares requeridos. Por otro lado,
el Juez B adoptó un enfoque más permisivo o alineado con los diseños de
ítems, con una alta tasa de aceptación sin cambios del 92.86~\%. Esta
evaluación indulgente se refleja en la ausencia total de cambios menores
y solo un 7.14~\% de ítems que necesitaron cambios mayores. Además, no
se registraron rechazos, lo que sugiere una percepción generalmente
favorable de los ítems presentados.

\begin{table}[htbp]
\centering
\caption{Control de aceptación de ítems de los jueces.}
\label{tab-07}
\begin{tabular}{lllll}
\toprule
Juez & \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Sin Cambios} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Con Cambios Menores} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptado Con Cambios Mayores} &
Rechazado \\
\midrule
Juez A & 33 \textbar{} 39.29~\% & 14 \textbar{} 16.67~\% & 35 \textbar{} 41.67~\% & 2 \textbar{} 2.38~\% \\
Juez B & 78 \textbar{} 92.86~\% & 0 & 6 \textbar{} 7.14~\% & 0 \\
\multicolumn{1}{>{\raggedright}p{2.1cm}}{Juez C (ChatGPT 4)} & 78 \textbar{} 92.86~\% & 3 \textbar{} 3.57~\% & 3 \textbar{} 3.57~\% & 0 \\
Media & 75~\% & 6.74~\% & 17.46~\% & 0.79~\% \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

No obstante, uno de los aspectos más relevantes fue observar la
consistencia entre los 84 ítems y los 3 jueces, el resultado fue una
concordancia baja (alfa = 0.228, véase \Cref{tab-08}), que según \textcite{Hayes2007}, el resultado varía de 0 a 1, donde valores cercanos
a 1 indican alta confiabilidad o acuerdo entre los jueces, y valores
cercanos a 0 indican lo contrario. En este sentido, como se ha analizado
anteriormente, parece existir una mayor concordancia entre el Juez B y
ChatGPT, que entre el Juez A y cualquiera de los otros dos jueces.

\begin{table}[htbp]
\centering
\caption{Resultados del alfa de Krippendorff entre los jueces.}
\label{tab-08}
\begin{tabular}{ll}
\toprule
Sujetos & 3 \\
Evaluadores & 84 \\
Alfa & 0.228 \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

Debido a los resultados del alfa de Krippendorf para tres jueces, se
realizó la prueba Kappa de Cohen entre los jueces A y B, y entre cada
juez y las evaluaciones de ChatGPT. Kappa de Cohen, según McHugh (2012),
es una medida de acuerdo entre dos jueces que tiene en cuenta el acuerdo
que podría ocurrir por azar. Un valor de Kappa de 1 indica un acuerdo
perfecto, mientras que un valor de 0 indica que cualquier acuerdo es
exactamente el que se esperaría por azar, y los valores negativos
indican desacuerdo. En la \Cref{tab-09} se pueden observar los resultados
entre jueces, donde:

\begin{itemize}
\item Juez A vs. Juez B: Hay un mínimo acuerdo entre estos dos jueces, que
	no es estadísticamente significativo, es decir, sus evaluaciones no
	concuerdan más allá de lo que se esperaría por azar.
\item Juez A vs. ChatGPT: Hay un mínimo, pero estadísticamente significativo
	acuerdo entre las evaluaciones del Juez A y ChatGPT. Aunque el acuerdo
	es mínimo, existe cierta concordancia más allá del azar.
\item Juez B vs. ChatGPT: Este par muestra un moderado acuerdo que es muy
	significativo estadísticamente. Indica que las evaluaciones del Juez B
	y ChatGPT concuerdan en cierta medida más allá de lo que se esperaría
	por azar. Lo que también podría significar un comportamiento
	específico a la de un humano con menos rigurosidad que, por ejemplo,
	un Juez A, más crítico.
\end{itemize}

\begin{table}[htbp]
\centering
\caption{Resultados de la prueba Kappa de Cohen entre jueces.}
\label{tab-09}
\begin{tabular}{llll}
\toprule
Comparación & Kappa & \multicolumn{1}{>{\raggedright}p{2cm}}{Significación (p-valor)} & Interpretación \\
\midrule
Juez A vs. Juez B & 0.075 & p = 0.092 & Mínimo acuerdo, no significativo \\
Juez A vs. ChatGPT & 0.089 & p = 0.017 & Mínimo acuerdo, significativo \\
Juez B vs. ChatGPT & 0.429 & p \textless{} 0.001 & Moderado acuerdo, muy significativo \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}



\subsection{Último jueceo}
En el proceso de segundo jueceo, los resultados variaron
significativamente entre los distintos diseñadores, pero homogeneizó el
resultado final del jueceo; considerando que aquí participaron tres
jueces además del A y B y se omitió la participación de ChatGPT. En la
Tabla 6 se puede ver que para el Diseñador A, 9 de sus 14 ítems (64.29
\%) pasaron a esta etapa, con un ítem (7.14~\%) requiriendo cambios
menores y otro ítem (7.14~\%) cambios mayores, mientras que la mayoría,
7 ítems (50~\%), no necesitaron ningún cambio. De manera similar, el
Diseñador C tuvo 8 ítems (57.14~\%) en la segunda evaluación, con un
ítem (7.14~\%) necesitando tanto cambios menores como mayores, y 7 ítems
(50~\%) sin cambios. El Diseñador E también mostró un patrón parecido,
con 9 ítems (64.29~\%) en el segundo jueceo, donde 1 ítem (7.14~\%)
necesitó cambios mayores y 7 ítems (50~\%) no requirieron
modificaciones.

\begin{table}[htbp]
\centering
\caption{Resumen del control de ítems que pasaron al segundo jueceo (grupal).}
\label{tab-10}
\begin{tabular}{llllll}
\toprule
 & \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados en primer jueceo} & 
 \multicolumn{1}{>{\raggedright}p{2cm}}{Total a segundo jueceo (grupal)} &
 \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Menores (Promedio)} & 
 \multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Mayores (Promedio)} & \multicolumn{1}{>{\raggedright}p{2cm}}{Sin cambio (Después del jueceo)} \\
\midrule
Diseñador A & 5 \textbar{} 35.71~\% & 9 \textbar{} 64.29~\% & 1	\textbar{} 7.14~\% & 1 \textbar{} 7.14~\% & 7 \textbar{} 50~\% \\
Diseñador B & 7 \textbar{} 50~\% & 7 \textbar{} 50~\% & 1 \textbar{} 7.14~\% & 0 & 7 \textbar{} 50~\% \\
Diseñador C & 6 \textbar{} 42.85~\% & 8 \textbar{} 57.14~\% & 1 \textbar{} 7.14~\% & 1 \textbar{} 7.14~\% & 7 \textbar{} 50~\% \\
Diseñador D & 4 \textbar{} 28.57~\% & 10 \textbar{} 71.43~\% & 1 \textbar{} 7.14~\% & 0 & 8 \textbar{} 57.14~\% \\
Diseñador E & 5 \textbar{} 35.71~\% & 9 \textbar{} 64.29~\% & 0 & 1 \textbar{} 7.14~\% & 7 \textbar{} 50~\% \\
Diseñador F & 3 \textbar{} 21.42~\% & 11 \textbar{} 78.57~\% & 1 \textbar{} 7.14~\% & 0 & 10 \textbar{} 71.43~\% \\
Total & 30 & 54 & 5 & 3 & 46 \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

Por otro lado, el Diseñador B tuvo una menor proporción de ítems que
pasaron a esta etapa, con solo 7 ítems (50~\%), y de estos, 1 ítem (7.14
\%) necesitó cambios menores y 7 ítems (50~\%) fueron aceptados sin
cambios. El Diseñador D mostró la mayor proporción de ítems en el
segundo jueceo, con 10 ítems (71.43~\%), y una alta tasa de aceptación
sin cambios, ya que 8 ítems (57.14~\%) no requirieron ajustes y solo 1
ítem (7.14~\%) necesitó cambios menores. Sobresaliendo en este proceso,
el Diseñador F presentó la mayor tasa de aceptación sin cambios, con 11
ítems (78.57~\%) pasando al segundo jueceo y 10 de ellos (71.43~\%)
aceptados tal como estaban inicialmente.

Finalmente, como se observa en la \Cref{tab-10}, la cantidad de ítems que
realmente sufrieron cambios fue un total de 8 de los 84, lo que equivale
a 9.52~\% del total. La segunda etapa de jueceo resultó muy necesaria
por la disparidad del jueceo. En este sentido, se puede concluir que el
Juez A tuvo una actitud muy crítica, lo que podría hacernos pensar en la
subjetividad del ser humano. Asimismo, en la \Cref{tab-11}, que representa el
ajuste final de los ítems después del jueceo grupal y antes de su
publicación y aplicación en un examen, se centra en los resultados
obtenidos tanto por los ítems diseñados por ChatGPT (A y D) como por los
diseñadores humanos (B, C, E, F).

\begin{table}[htbp]
\centering
\caption{Ajuste final, después de jueceo grupal, de los ítems.}
\label{tab-11}
\begin{tabular}{lllll}
\toprule
\multicolumn{1}{>{\raggedright}p{2cm}}{Grupo de Diseñadores} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Sin Cambios (Promedio)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Menores (Promedio)} &
\multicolumn{1}{>{\raggedright}p{2cm}}{Aceptados Con Cambios Mayores (Promedio)} & 
\multicolumn{1}{>{\raggedright}p{2cm}}{Rechazados (Promedio)} \\
\midrule
ChatGPT (A y D) & 85.71~\% & 7.14~\% & 3.57~\% & 3.57 \% \\
Humanos (B, C, E, F) & 89.2 8\% & 5.35~\% & 3.57~\% & 1.78 \% \\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{table}

Los ítems diseñados por ChatGPT mostraron una alta tasa de aceptación
sin cambios, con un 85.71~\% de los ítems considerados adecuados para su
uso sin necesidad de modificaciones adicionales. Esto indica que una
amplia mayoría de los ítems generados por ChatGPT alinearon
efectivamente con los estándares de evaluación desde su concepción
inicial. Además, un 7.14~\% de estos ítems requirieron cambios menores,
lo que sugiere que solo se necesitaron ajustes leves en una proporción
relativamente pequeña de casos. En cuanto a los cambios mayores, solo un
3.57~\% de los ítems necesitó este tipo de ajustes, y la misma
proporción (3.57~\%) fue rechazada, lo que refleja una tasa baja de
rechazo y una calidad general alta.

Por otro lado, los ítems diseñados por los diseñadores humanos
obtuvieron una tasa ligeramente superior de aceptación sin cambios,
alcanzando un 89.28~\%. Este resultado sugiere que los ítems humanos
estuvieron, en promedio, un poco más alineados con los criterios de
evaluación que los ítems de ChatGPT. Sin embargo, la diferencia no es
muy marcada, evidenciando una calidad comparable entre ambos grupos. La
tasa de ítems que requirieron cambios menores fue del 5.35~\%,
ligeramente inferior a la de ChatGPT, mientras que la proporción de
ítems que necesitaron cambios mayores fue idéntica a la de ChatGPT, 3.57
\%. La tasa de rechazo para los ítems humanos fue del 1.78~\%,
ligeramente inferior a la de ChatGPT, lo que indica un margen muy
estrecho en términos de calidad y aceptación general.
