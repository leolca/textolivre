\section{Introdução}\label{sec-intro}

A ambiguidade linguística, caracterizada pela possibilidade de uma palavra ou frase ter dois ou mais significados distintos em uma sentença, é um fenômeno complexo para os modelos de linguagem natural \cite{ortega2023linguistic}. Essa complexidade deriva da riqueza e sutilezas inerentes à estrutura e ao uso das línguas humanas, a partir da multiplicidade de significados que palavras e estruturas linguísticas podem assumir, dependendo do contexto em que são utilizadas. Mesmo os modelos de linguagem mais avançados, tais como Transformer \cite{vaswani2017attention} e BERT \cite{devlin2018bert}, enfrentam desafios ao lidar com diversos tipos de ambiguidade, devido à necessidade de considerar uma ampla variedade de contextos, conhecimentos prévios e nuances culturais que influenciam a interpretação das palavras e frases. Discernir o significado correto em um contexto específico demanda não apenas uma compreensão profunda da língua, mas também uma capacidade de inferência e abstração historicamente desafiadoras de replicar em sistemas computacionais \cite{ortega2023linguistic}. %Além disso, os modelos frequentemente apresentam dificuldades ao identificar e desambiguar um texto em situações mais complexas, nas quais múltiplas camadas de interpretação estão presentes.


A partir de 2010, a área de NLP testemunhou um grande avanço tecnológico com a evolução de técnicas de deep learning, principalmente em funções como sumarização de texto, classificação de tópicos, análise de sentimentos e sintetização de voz. Assim, foi possível experienciar tarefas com uma qualidade que ainda não era esperada até o momento. Desde o lançamento do ChatGPT e do Gemini\footnote[1]{O termo ChatPGT e Gemini serão tratados ao longo deste trabalho com pronomes masculinos por ser uma convenção adotada pelas demais literaturas brasileiras.}, modelos de linguagem instrucionais que têm revolucionado o mercado desde 2022, em consonância com o avanço tecnológico e o aumento da produtividade em diversas áreas do cotidiano, a inteligência artificial generativa tem impactado significativamente diversos setores, desde a educação até o mercado de trabalho. Essa influência se manifesta na distribuição de informações, na comunicação de ideias e na compreensão de dados discursivos, redefinindo a forma como interagimos e lidamos com o vasto espectro de informações disponíveis. 


Embora modelos avançados como o ChatGPT e o Gemini tenham apresentado progressos significativos na geração de linguagem natural, ainda subsistem incertezas quanto à sua capacidade de compreender fenômenos linguísticos complexos. Esses modelos, baseados em padrões estatísticos e processamento de grandes volumes de dados, não configuram uma verdadeira interlocução com o usuário, uma vez que anulam componentes fundamentais da comunicação humana, como gestos, entonação e expressões faciais. Além disso, eles não possuem uma compreensão do senso comum, o que frequentemente resulta na geração de dados que não refletem adequadamente a realidade compartilhada pelos seres humanos \cite{itankar2020ambiguity,singh2015role,chaplot2015unsupervised,agirre1997proposal}.

Por outro lado, a capacidade de processamento de um grande volume de dados empíricos provida pelos LLMs também tem oferecido oportunidades de reflexão sobre a relação entre teoria e dados, que é diferente a depender da abordagem assumida, seja indutivo, seja dedutivo, seja de orientação funcionalista, seja de orientação formalista. Mas há também abordagens que descrevem padrões fenômenos sem assumir uma teoria para língua, como é o caso de LLMs. \textcite{piantadosi2023modern} afirma que LLMs têm conseguido resultados de desvelamento da gramática sem usar nenhum dos métodos assumidos como necessários para a descrição linguística por humanos. Por outro lado, resultados de estudos que observam como LLMs lidam com tarefas linguísticas cotidianas, como a leitura de palavras que tiveram letras sistematicamente trocadas por números, como "l3tr4 tr0c4d4" (letra trocada) \cite{marcus2023sentence}, sugerem que, por não terem cognição fundamentada, LLMs não podem tirar proveito desses recursos e, em vez disso, dependem apenas de associações fixas entre palavras representadas e vetores de palavras. Os autores evidenciam um paradoxo: se os LLMs supostamente emulam a linguagem humana, e seu desempenho supostamente mostra habilidades que superaram as dos seres humanos, ao mesmo tempo que estes mesmos LLMs não conseguem fornecer respostas precisas em tarefas muito básicas de compreensão da linguagem, como é o caso da tarefa letra trocada, sendo necessários mais estudos em mais tarefas, como a de resolução de ambiguidades, que podem contribuir para a compreensão da base cognitiva da faculdade humana da linguagem. 

Do ponto de vista linguístico, é improvável que esses modelos de linguagem consigam reproduzir, em sua totalidade, as capacidades linguísticas humanas. A significação, por exemplo, é intrinsecamente multimodal, envolvendo não apenas a linguagem verbal, mas também elementos contextuais como expressões faciais, postura corporal e até detalhes sutis como o vestuário do interlocutor, no caso de interações orais \cite{freitag2022linguistic}. No contexto da comunicação escrita, aspectos como a cor da fonte, o tipo de papel e o suporte do texto podem influenciar a interpretação do significado. Além disso, fatores como variação linguística, tom de voz e o uso de linguagem figurativa são determinantes para a construção de sentido, o que torna a completa emulação da experiência linguística humana por modelos artificiais uma tarefa extremamente desafiadora. 

Essas dificuldades afetam a capacidade dos modelos de linguagem de processar adequadamente ambiguidades linguísticas e superar desafios já observados em modelos tradicionais, que também enfrentam limitações. Além disso, a maior parte dos estudos desenvolvidos até o momento têm como foco a língua inglesa \cite{ortega2023linguistic}. Análises mais aprofundadas no contexto do português brasileiro, uma língua de baixos recursos linguísticos \cite{finger2021inteligencia, freitag2022sociolinguistic}, ainda não foram conduzidas, revelando a importância de investigações neste campo.

Nesse contexto, este trabalho tem como objetivo responder as seguintes perguntas:

\begin{enumerate}
    \item Qual é a precisão dos modelos na detecção de ambiguidade linguística em frases do Português Brasileiro?    
    \item Os modelos conseguem desambiguar adequadamente as sentenças?    
    \item Qual dos modelos percebe melhor os fenômenos de homonímia e polissemia?    
    \item Quais padrões de ambiguidade os modelos ChatGPT e Gemini demonstram conhecer na
    geração de frases ambíguas?
\end{enumerate}


O estudo de ambiguidade é particularmente complexo, por envolver uma gama de variáveis que interferem, desde a natureza do item lexical, passando pela sintaxe da sentença, e envolvendo o conhecimento de mundo e experiência pessoal de cada falante. Além disso,  há um paradoxo a ser superado: um humano pode perceber ambiguidade e não saber explicá-la, enquanto a IA pode saber explicar o que é uma ambiguidade, mas não saber reconhecê-la.  
Assumindo que as IAs são capazes de imitar em grande medida o processamento da linguagem humana e que têm o potencial de fornecer informações sobre a forma como as pessoas aprendem e utilizam a linguagem \cite{cai2023does} conduzimos um estudo com a realização de quatro tarefas. 
Utilizando um conjunto de sentenças com e sem ambiguidade criado por nós, verificamos a consistência das respostas dos modelos ao fazer as mesmas perguntas duas vezes, em momentos distintos, e contrastamos algumas inconsistências nas respostas obtidas. 