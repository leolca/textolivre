\documentclass[portuguese]{textolivre}

% metadata
\journalname{Texto Livre}
\thevolume{18}
%\thenumber{1} % old template
\theyear{2025}
\receiveddate{\DTMdisplaydate{2024}{6}{28}{-1}}
\accepteddate{\DTMdisplaydate{2024}{9}{17}{-1}}
\publisheddate{\today}
\corrauthor{Lavínia Moraes}
\articledoi{10.1590/1983-3652.2025.53181}
%\articleid{NNNN} % if the article ID is not the last 5 numbers of its DOI, provide it using \articleid{} commmand 
% list of available sesscions in the journal: articles, dossier, reports, essays, reviews, interviews, editorial
\articlesessionname{articles}
\runningauthor{Moraes et al.}
%\editorname{Leonardo Araújo} % old template
\sectioneditorname{Daniervelin Pereira}
\layouteditorname{Leonardo Araújo}

\title{Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)}
\othertitle{Linguistic ambiguity analysis in large language models (LLMs)}

\author[1]{Lavínia de Carvalho Moraes~\orcid{0000-0002-4934-8505}\thanks{Email: \href{mailto:l237294@dac.unicamp.br}{l237294@dac.unicamp.br}}}
\author[1]{Irene Cristina Silvério~\orcid{0000-0002-7737-7469}\thanks{Email: \href{mailto:i169329@dac.unicamp.br}{i169329@dac.unicamp.br}}}
\author[1]{Rafael Alexandre Sousa Marques~\orcid{0000-0003-2807-037X}\thanks{Email: \href{mailto:rafaelalexandre001@gmail.com}{rafaelalexandre001@gmail.com}}}
\author[1]{Bianca de Castro Anaia~\orcid{0000-0001-9330-0288}\thanks{Email: \href{mailto:biancaanaia@gmail.com}{biancaanaia@gmail.com}}}
\author[1]{Dandara Freitas de Paula~\orcid{0000-0002-4995-1582}\thanks{Email: \href{mailto:d206236@dac.unicamp.br}{d206236@dac.unicamp.br}}}
\author[1]{Maria Carolina Schincariol de Faria~\orcid{0000-0003-0849-7237}\thanks{Email: \href{mailto:mariaschincariol@outlook.com}{mariaschincariol@outlook.com}}}
\author[1]{Iury Cleveston~\orcid{0000-0002-6010-4624}\thanks{Email: \href{mailto:iury@attenty.com.br}{iury@attenty.com.br}}}
\author[1]{Alana de Santana Correia~\orcid{0000-0002-7417-3727}\thanks{Email: \href{mailto:alana@attenty.com.br}{alana@attenty.com.br}}}
\author[2]{Raquel Meister Ko Freitag~\orcid{0000-0002-4972-4320}\thanks{Email: \href{mailto:rkofreitag@uol.com.br}{rkofreitag@uol.com.br}}}

\affil[1]{Attenty Sistemas de Software, Análise de dados, Campinas, SP, Brasil.}
\affil[2]{Universidade Federal de Sergipe, Departamento de Letras Vernáculas, Sergipe, SE, Brasil.}

\addbibresource{article.bib}

\usepackage{csquotes}
\usepackage{subcaption}
\usepackage{longtable}
\usepackage{array}

\begin{document}
\maketitle

\begin{polyabstract}
\begin{abstract}

A ambiguidade linguística ainda é um grande desafio para sistemas de processamento de linguagem natural (NLP) apesar dos avanços em arquiteturas como Transformers e BERT. Inspirado pelo êxito recente dos modelos instrucionais ChatGPT (versão 3.5) e Gemini (denominado Bard até 2023), este trabalho visa analisar e discutir a ambiguidade linguística nesses modelos a partir de três tipos de ambiguidade no Português Brasileiro: semântica, sintática e lexical. Para isso, foi desenvolvido um corpus com 120 frases ambíguas e não ambíguas, submetidas aos modelos para tipificação, explicação e desambiguação. Também foi explorada a capacidade de geração de frases ambíguas, solicitando a geração de conjuntos de frases para cada tipo de ambiguidade. Os resultados foram analisados qualitativamente, com base em referenciais linguísticos reconhecidos, e quantitativamente pela acurácia das respostas obtidas.  Evidenciamos que equívocos e deficiências nas respostas permanecem mesmo em modelos mais sofisticados, como ChatGPT e Gemini, com explicações frequentemente inconsistentes. A acurácia foi de no máximo 49,58\%, apontando a necessidade de estudos descritivos para o aprendizado supervisionado.



\keywords{Ambiguidade \sep Modelos de linguagem \sep ChatGPT \sep Gemini}
\end{abstract}

\begin{english}
\begin{abstract}
Linguistic ambiguity continues to represent a significant challenge for natural language processing (NLP) systems, notwithstanding the advancements in architectures such as Transformers and BERT. Inspired by the recent success of instructional models like ChatGPT and Gemini (Named Bard in 2023.), this study aims to analyze and discuss linguistic ambiguity within these models, focusing on three types prevalent in Brazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a corpus comprising 120 sentences, both ambiguous and unambiguous, for classification, explanation, and disambiguation. The models' capability to generate ambiguous sentences was also explored by soliciting sets of sentences for each type of ambiguity. The results underwent qualitative analysis, drawing on recognized linguistic references, and quantitative assessment based on the accuracy of the responses obtained. It was evidenced that even the most sophisticated models, such as ChatGPT and Gemini, exhibit errors and deficiencies in their responses, with explanations often providing inconsistent. Furthermore, the accuracy peaked at 49.58\%,indicating the need for descriptive studies for supervised learning. 

\keywords{Ambiguity \sep Language models \sep ChatGPT \sep Gemini}

\end{abstract}
\end{english}
% if there is another abstract, insert it here using the same scheme
\end{polyabstract}

\input{introducao}
\input{referencial_teorico}
\input{metodologia}
\input{resultados}



\section{Conclusão}\label{sec-conclusao}

Nossos resultados indicaram melhorias significativas entre os diferentes modelos, assim como diversas vantagens e limitações. Nesse sentido, nosso trabalho apresenta as seguintes contribuições: 1) disponibiliza um conjunto de dados formatado para testar a ambiguidade linguística em modelos de linguagem natural no português brasileiro, que até o nosso conhecimento é o primeiro proposto na literatura; 2) é o primeiro trabalho a informar à comunidade científica sobre as limitações do ChatGPT e do Gemini em compreender fenômenos linguísticos complexos, como a ambiguidade na língua portuguesa; 3) apresenta uma metodologia para avaliar esses modelos quanto ao fenômeno da ambiguidade; e 4) demonstra, por meio de resultados qualitativos e quantitativos, qual dos dois modelos lida melhor com esses fenômenos linguísticos.

A análise do fenômeno de ambiguidade linguística nos modelos instrucionais ChatGPT e Gemini, cujas versões 3.5 e Bard, respectivamente, foram submetidos a quatro tarefas referentes à detecção, tipificação, desambiguação e geração de frases ambíguas. Os resultados obtidos mostraram que ambiguidade linguística ainda é um grande desafio para estas versões de modelos de processamento de linguagem natural, demandando ainda estudos e implementações para o aprimoramento.

Os modelos apresentaram baixa acurácia e baixo desempenho em praticamente todas as tarefas testadas. Na detecção de ambiguidade, o ChatGPT conseguiu uma acurácia de 28,75\% e o Gemini 49,58\%. Os modelos também apresentaram uma superinterpretação de sentenças não ambíguas, detectando e desambiguando frases que não tinham qualquer tipo de ambiguidade e que seres humanos facilmente conseguem interpretar apenas um sentido nas sentenças. Os melhores resultados obtidos ocorreram na tarefa de desambiguação e classificação onde a ambiguidade residia apenas no item lexical, demonstrando que é o tipo de ambiguidade em que os modelos tem mais facilidade para lidar. 

Merece destaque o fato de que, apesar da maior facilidade em lidar com ambiguidade lexical, os modelos tiveram o pior desempenho na geração de frases com ambiguidade desse tipo. Algo similar ocorreu com as frases de categoria semântica, em que os modelos confundiram com os padrões de ambiguidade estrutural ou geraram a maioria das frases sem ambiguidade. Por outro lado, ocorreu um melhor desempenho na geração de frases com ambiguidade sintática, porém ainda com uma interpretação errada sobre a origem da ambiguidade em várias frases, demonstrando que os modelos conseguiram gerar algumas frases corretamente mas ainda não conseguem explicar com clareza as causas da ambiguidade sintática. Outro ponto que chamou a atenção foi a tendência da ChatGPT em personificar alguns elementos inanimados para atribuir ambiguidade às frases, algo que um ser humano jamais faria. Os resultados relativos à identificação de ambiguidades se alinham ao que  \cite{marcus2023sentence} obtiveram com a tarefa de letra trocada: enquanto seres humanos são excelentes nessa tarefa, LLMs apresentam dificuldades. A resolução de ambiguidades é então uma das habilidades que ainda estão faltando no estado atual de desenvolvimento desses modelos.

Em suma, os resultados mostram que estas versões dos modelos instrucionais ainda estão distantes de emular plenamente a capacidade cognitiva dos seres humanos, não só envolvendo a relação entre linguagem e identidade social \cite{freitag2021preconceito}, mas também o uso na interação social, o que requer a compreensão de ambiguidades. No entanto, os resultados também sinalizam um progresso inicial na compreensão e aquisição do senso comum a respeito de como a linguagem humana funciona e reiteram a importância dos estudos descritivos em línguas ainda com poucos recursos, como é o caso do português \cite{finger2021inteligencia, freitag2022sociolinguistic}, para aprimoramento.

\printbibliography\label{sec-bib}
%conceptualization,datacuration,formalanalysis,funding,investigation,methodology,projadm,resources,software,supervision,validation,visualization,writing,review
\begin{contributors}[sec-contributors]
\authorcontribution{Lavínia de Carvalho Moraes}[conceptualization,datacuration,investigation,writing,review]
\authorcontribution{Irene Cristina Silvério}[datacuration,investigation,writing]
\authorcontribution{Rafael Alexandre Sousa Marques}[datacuration,investigation,writing]
\authorcontribution{Bianca de Castro Anaia}[datacuration,investigation,writing]
\authorcontribution{Dandara Freitas de Paula}[datacuration,investigation,writing]
\authorcontribution{Maria Carolina Schincariol de Faria}[datacuration,investigation,writing]
\authorcontribution{Iury Cleveston}[validation,resources,funding]
\authorcontribution{Alana de Santana Correia}[conceptualization,validation,resources,methodology,supervision,writing,review]
\authorcontribution{Raquel Meister Ko Freitag}[conceptualization,validation,methodology,review]
\end{contributors}

\input{anexos}
\end{document}
