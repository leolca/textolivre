% !TEX TS-program = XeLaTeX
% use the following command:
% all document files must be coded in UTF-8
\documentclass[spanish]{textolivre}
% build HTML with: make4ht -e build.lua -c textolivre.cfg -x -u article "fn-in,svg,pic-align"

\journalname{Texto Livre}
\thevolume{19}
%\thenumber{1} % old template
\theyear{2026}
\receiveddate{\DTMdisplaydate{2025}{3}{2}{-1}} % YYYY MM DD
\accepteddate{\DTMdisplaydate{2025}{3}{31}{-1}}
\publisheddate{\DTMdisplaydate{2025}{11}{23}{-1}}
\corrauthor{Ernesto Colomo}
\articledoi{10.1590/1983-3652.2026.57860}
%\articleid{NNNN} % if the article ID is not the last 5 numbers of its DOI, provide it using \articleid{} commmand 
% list of available sesscions in the journal: articles, dossier, reports, essays, reviews, interviews, editorial
\articlesessionname{articles}
\runningauthor{Rubio-Gragera, Palacios-Rodríguez y Colomo-Magaña} 
%\editorname{Leonardo Araújo} % old template
\sectioneditorname{Hugo Heredia Ponce~\orcid{0000-0003-3657-1369}}
\layouteditorname{Leonardo Carneiro de Araújo~\orcid{0000-0003-3884-2177}}

\title{Competencia digital e inteligencia artificial: diseño y validación de un instrumento para alumnado de Educación Secundaria mediante juicio de expertos}
\othertitle{Competência digital e inteligência artificial: design e validação de um instrumento para alunos do ensino médio por meio de julgamento de especialistas}
\othertitle{Digital competence and artificial intelligence: design and validation of an instrument for secondary school students through expert judgement}
% if there is a third language title, add here:
%\othertitle{Artikelvorlage zur Einreichung beim Texto Livre Journal}

\author[1]{María Rubio-Gragera~\orcid{0000-0002-8311-8498}\thanks{Email: \href{mailto:mrubiogr@uma.es}{mrubiogr@uma.es}}}
\author[2]{Antonio de Padua Palacios-Rodríguez ~\orcid{0000-0002-0689-6317}\thanks{Email: \href{mailto:aprodriguez@us.es}{aprodriguez@us.es}}}
\author[1]{Ernesto Colomo-Magaña~\orcid{0000-0002-3527-7937}\thanks{Email: \href{mailto:ecolomo@uma.es}{ecolomo@uma.es}}}
\affil[1]{Universidad de Málaga, Facultad de Ciencias de la Educación, Departamento de Didáctica y Organización Escolar, Campus de Teatinos, Málaga, España.}
\affil[2]{Universidad de Sevilla, Facultad de Ciencias de la Educación, Departamento de Didáctica y Organización Escolar, Sevilla, España.}

\addbibresource{article.bib}
% use biber instead of bibtex
% $ biber article

% used to create dummy text for the template file
\definecolor{dark-gray}{gray}{0.35} % color used to display dummy texts
\usepackage{lipsum}
\SetLipsumParListSurrounders{\colorlet{oldcolor}{.}\color{dark-gray}}{\color{oldcolor}}

% used here only to provide the XeLaTeX and BibTeX logos
\usepackage{hologo}

% if you use multirows in a table, include the multirow package
\usepackage{multirow}

% provides sidewaysfigure environment
\usepackage{rotating}

% CUSTOM EPIGRAPH - BEGIN 
%%% https://tex.stackexchange.com/questions/193178/specific-epigraph-style
\usepackage{epigraph}
\renewcommand\textflush{flushright}
\makeatletter
\newlength\epitextskip
\pretocmd{\@epitext}{\em}{}{}
\apptocmd{\@epitext}{\em}{}{}
\patchcmd{\epigraph}{\@epitext{#1}\\}{\@epitext{#1}\\[\epitextskip]}{}{}
\makeatother
\setlength\epigraphrule{0pt}
\setlength\epitextskip{0.5ex}
\setlength\epigraphwidth{.7\textwidth}
% CUSTOM EPIGRAPH - END

% to use IPA symbols in unicode add
%\usepackage{fontspec}
%\newfontfamily\ipafont{CMU Serif}
%\newcommand{\ipa}[1]{{\ipafont #1}}
% and in the text you may use the \ipa{...} command passing the symbols in unicode

% LANGUAGE - BEGIN
% ARABIC
% for languages that use special fonts, you must provide the typeface that will be used
% \setotherlanguage{arabic}
% \newfontfamily\arabicfont[Script=Arabic]{Amiri}
% \newfontfamily\arabicfontsf[Script=Arabic]{Amiri}
% \newfontfamily\arabicfonttt[Script=Arabic]{Amiri}
%
% in the article, to add arabic text use: \textlang{arabic}{ ... }
%
% RUSSIAN
% for russian text we also need to define fonts with support for Cyrillic script
% \usepackage{fontspec}
% \setotherlanguage{russian}
% \newfontfamily\cyrillicfont{Times New Roman}
% \newfontfamily\cyrillicfontsf{Times New Roman}[Script=Cyrillic]
% \newfontfamily\cyrillicfonttt{Times New Roman}[Script=Cyrillic]
%
% in the text use \begin{russian} ... \end{russian}
% LANGUAGE - END

% EMOJIS - BEGIN
% to use emoticons in your manuscript
% https://stackoverflow.com/questions/190145/how-to-insert-emoticons-in-latex/57076064
% using font Symbola, which has full support
% the font may be downloaded at:
% https://dn-works.com/ufas/
% add to preamble:
% \newfontfamily\Symbola{Symbola}
% in the text use:
% {\Symbola }
% EMOJIS - END

% LABEL REFERENCE TO DESCRIPTIVE LIST - BEGIN
% reference itens in a descriptive list using their labels instead of numbers
% insert the code below in the preambule:
%\makeatletter
%\let\orgdescriptionlabel\descriptionlabel
%\renewcommand*{\descriptionlabel}[1]{%
%  \let\orglabel\label
%  \let\label\@gobble
%  \phantomsection
%  \edef\@currentlabel{#1\unskip}%
%  \let\label\orglabel
%  \orgdescriptionlabel{#1}%
%}
%\makeatother
%
% in your document, use as illustraded here:
%\begin{description}
%  \item[first\label{itm1}] this is only an example;
%  % ...  add more items
%\end{description}
% LABEL REFERENCE TO DESCRIPTIVE LIST - END


% add line numbers for submission
%\usepackage{lineno}
%\linenumbers

\begin{document}
\maketitle

\begin{polyabstract}
\begin{abstract}
Considerando el impacto de la inteligencia artificial (IA) en la educación, es preciso que los implicados en el proceso de enseñanza-aprendizaje mejoren sus habilidades digitales para su correcto uso. El propósito de este trabajo fue validar un cuestionario para evaluar la competencia digital en IA (DigCompIA) en alumnado de Educación Secundaria. Se utilizó el método de juicio de expertos, aplicando el Coeficiente de Competencia Experta (CCE) para la selección de los evaluadores del cuestionario. Los resultados reflejaron altas puntuaciones en los factores de relevancia, representatividad y claridad del instrumento en las dimensiones de alfabetización digital, resolución de problemas y creación de contenidos, siendo precisos algunos ajustes en los ítems que conforman la dimensión de seguridad digital. Se concluye que el instrumento es válido, según los expertos, a nivel de contenido, siendo preciso su aplicación con estudiantes de educación secundaria para validarlo psicométricamente. 

\keywords{Inteligencia artificial \sep Competencia digital \sep Cuestionario \sep Juicio de expertos}
\end{abstract}

\begin{portuguese}
\begin{abstract}
Considerando o impacto da inteligência artificial (IA) na educação, é essencial que os envolvidos no processo de ensino-aprendizagem aprimorem suas habilidades digitais para seu uso adequado. O objetivo deste estudo foi validar um questionário para avaliar a competência digital em IA (DigCompIA) entre alunos do ensino médio. O método de julgamento de especialistas foi utilizado, empregando o Coeficiente de Competência Especialista (CCE) para a seleção dos avaliadores do questionário. Os resultados mostraram altas pontuações nos fatores de relevância, representatividade e clareza do instrumento nas dimensões de alfabetização digital, resolução de problemas e criação de conteúdo, sendo necessários alguns ajustes nos itens que compõem a dimensão de segurança digital. Conclui-se que o instrumento é válido, segundo os especialistas, em nível de conteúdo, sendo necessária sua aplicação com alunos do ensino médio para validá-lo psicometricamente.

\keywords{Inteligência artificial \sep Competência digital \sep Questionário \sep Julgamento de especialistas}
\end{abstract}
\end{portuguese}

\begin{english}
\begin{abstract}
Considering the impact of artificial intelligence (AI) on education, it is essential for those involved in the teaching-learning process to improve their digital skills for its proper use. The purpose of this study was to validate a questionnaire to assess digital competence in AI (DigCompIA) among secondary education students. The expert judgment method was used, employing the Expert Competence Coefficient (CCE) to select the questionnaire evaluators. The results showed high scores in the factors of relevance, representativeness, and clarity of the instrument in the dimensions of digital literacy, problem-solving, and content creation, while some adjustments were needed in the items related to the digital security dimension. It is concluded that the instrument is valid, according to experts, at the content level, and its application with secondary education students is necessary for psychometric validation.

\keywords{Artificial intelligence \sep Digital competence \sep Questionnaire \sep Expert judgment}
\end{abstract}
\end{english}
% if there is another abstract, insert it here using the same scheme
\end{polyabstract}

\section{Introducción}\label{sec-intro}
La inteligencia artificial (IA, en adelante) ha incrementado su relevancia en el contexto educativo y en los procesos de enseñanza-aprendizaje en todos los niveles \cite{floresvivar2023}. Se trata de una herramienta revolucionaria en el sector de la formación, que permite personalizar los procesos formativos, a nivel de retroalimentación y accesibilidad a los recursos \cite{gragera2024}. No obstante, también existen corrientes que subrayan los problemas y aspectos a considerar en el uso de la IA, como el cambio en el rol docente \cite{morais2024} o las malas prácticas y el plagio derivado de su uso irresponsable \cite{guillen2025}. 

Es tal su incidencia que ha sido preciso establecer normativas y legislaciones para regular cómo utilizar la IA en Educación, incluida la etapa de Secundaria \cite{glushkova2023}. A nivel internacional, la guía realizada por la UNESCO \cite{miao2024} ha definido políticas para regular el uso de la IA generativa, por su impacto en factores educativos clave como la personalización de la enseñanza o los procesos de autoaprendizaje. A nivel europeo, el Reglamento (UE) 2024/1689 \cite{ue2024aiact} pone de manifiesto la incidencia que el uso de la IA puede tener en la educación. Junto a estas normativas, autores como \textcite{leta2023,yan2024} inciden en la necesidad de definir marcos regulatorios a nivel ético que orienten una incorporación sostenible y beneficiosa de la IA en educación.

Además de las regulaciones y normativas, desde la investigación educativa ya se ha abordado el fenómeno de la IA desde múltiples perspectivas: la incidencia de la IA generativa, como GPT en la universidad \cite{alenezi2023,gonzalez2024} y Educación Secundaria \cite{valeri2025}, o Stable difussion para la generación de imágenes con estudiantes de secundaria \cite{saz2025}; la revolución a nivel de innovación que conlleva la IA \cite{villegas2024}; la aceptación para su uso en el ámbito educativo \cite{cabero2024}; los problemas éticos y las prácticas deshonestas derivados del uso de la IA en educación \cite{sahin2024,velez2024}; o su incidencia en la etapa universitaria \cite{lopez2024,casillasmartin2025}. Situando más el foco en Educación Secundaria, también se han analizado las actitudes del alumnado respecto a la IA \cite{pande2023} y su uso para la práctica de conversaciones en inglés \cite{annamalai2023}. Pese a ello, son pocos los estudios dedicados aún a esta etapa. A ello hay que sumar que, a nivel general, el ámbito de la competencia digital necesaria para el uso de la IA no está copando las principales vías de estudio \cite{rubio2025}.

Si bien la competencia digital ha sido uno de los principales campos de estudio dentro de la tecnología educativa en los últimos años \cite{aguilar2021,civico2024,colomo2023,guillen2024a,guillen2024b,marin2021,palacios2025,pinto2023,romero2024,tomczyk2023,villen2024}, el vínculo entre estas competencias y el uso de la IA no se está expandiendo considerablemente. Y es que la competencia digital es uno de los ocho estándares estipulados por la \textcite{comission2022} para el aprendizaje permanente, plasmado en el DigComp como marco común para la competencia digital ciudadana. Conformado por 5 áreas y un total de 20 factores, se han realizado adaptaciones y matizaciones para diferentes agentes o etapas, como es el caso de la educación secundaria \cite{guitert2021}. De momento, solo tenemos una versión actualizada del DigComp 2.2, donde se ha incluido el factor de la inteligencia artificial, considerando su impacto en cada una de las áreas y competencias \cite{vuorikari2022}.

Sin embargo, no existen antecedentes ni instrumentos que estudien de forma específica la competencia digital para el uso de la IA por el alumnado de secundaria, siendo una de las aportaciones que realiza este trabajo.

Sí que hay literatura centrada en el análisis de la competencia digital del alumnado de secundaria en diferentes partes del mundo. La investigación de \textcite{rodriguez2024}, en Colombia, con 777 estudiantes de Educación Secundaria, reflejó un nivel básico de competencia digital, precisando de políticas concretas que mejoren dicho nivel. En Perú, la alfabetización mediática e informacional era un terreno de grandes mejoras entre los 1250 estudiantes de secundaria que analizaron \textcite{turpo2023}, determinado por aspectos como la edad, el acceso a equipos o el sexo. En Portugal, la percepción que el alumnado de secundaria tiene de internet y de su competencia digital es clave para el desarrollo de su competencia digital \cite{senos2024}. En España, se han realizado estudios sobre diferentes áreas del DigComp. Centrados en la competencia digital de búsqueda y selección de información, \textcite{valverde2020} hallaron que 77 estudiantes de Secundaria (3º ESO) demostraban un nivel básico sobre dicha competencia en el ámbito de las ciencias naturales. Respecto al área de seguridad, \textcite{garciavalcarcel2019} validaron una prueba para comprobar los conocimientos del alumnado de educación secundaria. Con una muestra de 97 estudiantes de secundaria, el trabajo de \textcite{lopez2021} halló mejoras en la competencia digital de los participantes en relación con la fluidez tecnológica, la colaboración y el pensamiento crítico, así como en la ciudadanía digital.

Estos trabajos nos indican que, en pleno auge de la inteligencia artificial, los niveles de competencia digital del alumnado de secundaria no son suficientes, debiendo incorporar a estas destrezas y habilidades el uso responsable de la IA. 

Por tanto, pese al impacto de la IA en las instituciones, agentes educativos y diferentes etapas obligatorias y no obligatorias del sistema, encontramos aspectos que aún deben abordarse desde el terreno científico con premura. En este sentido, la falta de instrumentos validados que permitan medir la competencia digital del alumnado de la etapa de educación secundaria en el uso de la inteligencia artificial nos impide tomar conciencia de sus habilidades y destrezas. Dicha circunstancia dificulta la implementación de políticas educativas y procesos formativos específicos que respondan a esta necesidad de aprendizaje, tomando como referencia los niveles reales de uso y conocimiento. Debido a ello, es preciso que desde el terreno de la investigación educativa se trabaje en el diseño, construcción y validación de instrumentos que respondan a estos requerimientos. El objetivo de este estudio es validar por juicio de expertos una propuesta de cuestionario para medir la competencia digital del alumnado en inteligencia artificial.

\subsection{Trabajos relacionados}

Si bien no hay precedentes respecto a instrumentos validados sobre la competencia digital del alumnado de secundaria para el uso de la IA, sí encontramos trabajos que abordan cada uno de los elementos que conforman nuestro objeto de estudio por separado. 

Respecto al nivel de competencia digital en estudiantes de Educación Secundaria, \textcite{iglesias2021} elaboró un cuestionario ad hoc para evaluar las seis competencias del área de comunicación del DigComp. Con una muestra de 609 estudiantes entre 11 y 13 años, el instrumento logró alcanzar índices adecuados de discriminación y dificultad, así como una validez adecuada por juicio de expertos y análisis factorial. A pesar de que se trata de un instrumento interesante, solo aborda una de las áreas del DigComp. Por otra parte, \textcite{garciavalcarcel2020} generaron un instrumento basado en el DigComp a partir de indicadores que permitieron evaluar las competencias digitales del alumnado de secundaria. Dicha herramienta fue validada por juicio de expertos ($n=77$), constatando que las competencias del DigComp estaban representadas por los ítems que conformaban el INCODES, sirviendo para evaluar el nivel de las destrezas digitales del alumnado en dicha etapa educativa. 

En cuanto a las herramientas sobre inteligencia artificial, el trabajo de \textcite{saz2024} validó un cuestionario TPACK para docentes sobre el uso de IA generativa, logrando una alta consistencia interna para evaluar el conocimiento tecnológico, pedagógico y disciplinar en contextos de IA. De manera específica, el estudio de \textcite{ng2024} validó un instrumento de 32 ítems sobre alfabetización en IA (AILQ) con una muestra de 363 estudiantes de secundaria de Hong Kong, logrando una escala fiable. Por tanto, no encontramos ni excesivos instrumentos sobre competencia digital para alumnado de secundaria, y apenas una herramienta sobre IA para dicho alumnado, sin encontrar instrumentos ya validados o en proceso de validación que aúnen ambos aspectos. 

Si atendemos al proceso de validación por el denominado coeficiente de experto, son varios los trabajos que han utilizado esta técnica para corroborar la valoración y juicio de los expertos considerados. En España, tuvo sus inicios con el trabajo de \textcite{cabero2013a} para validar por juicio de experto un entorno personal de aprendizaje (PLE), consiguiendo que, con esta técnica, se discriminara la mejor forma de seleccionar a los expertos. También \textcite{cabero2021a} lo utilizaron para validar las posibilidades de un t-MOOC para el desarrollo de competencias digitales en docentes según el Marco DigCompEdu, logrando una muestra de 172 expertos que valoraron muy positivamente las posibilidades del t-MOOC. Siguiendo con el marco DigCompEdu, \textcite{cabero2021b} también utilizaron este coeficiente para comparar y evaluar la viabilidad de este marco de competencia digital para docentes y el Marco de Competencia Digital Docente del INTEF. La muestra de 275 expertos avaló que el DigCompEdu es el marco mejor valorado. Recientemente, ha sido utilizado por \textcite{leon2024} con 38 expertos para validar un instrumento que permita evaluar apps móviles para el aprendizaje de la Educación Musical, encontrando resultados muy positivos para que los docentes utilicen esta herramienta.


\section{Metodología}
Este estudio propone validar el Cuestionario de Competencia Digital del Alumnado en Inteligencia Artificial (CompDigIA) mediante la técnica de juicio de expertos. El juicio de expertos se define como el “proceso de solicitar a un grupo de personas especializadas una valoración sobre un objeto, instrumento, material didáctico o un aspecto específico de interés” \cite[p.~14]{cabero2013b}. Se trata de una técnica con tradición en la investigación educativa \cite{galicia2017,robles2015} y relacionada con el método Delphi \cite{mengual2016,lopez2018}.

Uno de los principales desafíos de este enfoque radica en la ambigüedad del concepto de persona "experta". No existe una definición única y universalmente aceptada que establezca con precisión sus características esenciales. Como consecuencia, la validez de los resultados obtenidos depende en gran medida de la calidad de los expertos seleccionados para el proceso de evaluación.

Para abordar este desafío, se emplean distintos procedimientos de selección, que van desde la revisión del perfil del experto hasta el uso de métodos más sofisticados, como el usado en este estudio: Coeficiente de Competencia Experta (CCE) \cite{cabero2013a,cabero2021a}.

El CCE se calcula mediante la siguiente fórmula: $K = \frac{1}{2} (Kc + Ka)$.
Kc representa el "coeficiente de conocimiento", que se obtiene a partir de la puntuación otorgada directamente por el experto en una pregunta específica, siguiendo lo expuesto en \textcite[p.~12]{cabero2021a}:
\begin{enumerate}[label=\Alph*)]
    \item Marque en la casilla que le corresponde el grado de conocimiento que usted posee acerca de temáticas como las siguientes: formación del profesorado en TIC, competencias digitales, alfabetización digital... Valórese en una escala de 0 a 10 (considerando el 0 como no tener absolutamente ningún conocimiento y 10 de pleno conocimiento del estado de la cuestión).

    Ka, el coeficiente de argumentación, se calcula sumando las puntuaciones asignadas por el experto a las diferentes fuentes de conocimiento, según los coeficientes establecidos por \textcite{cabero2013a}. Para ello, se utiliza la siguiente pregunta \cite[p.~13]{cabero2021a}.

    \item Autovalore el grado de influencia (bajo, medio o alto) que han tenido las siguientes fuentes en sus conocimientos y criterios sobre la formación del profesorado en TIC, competencias y alfabetización digital:
\begin{enumerate}
    \item Análisis teóricos realizados por usted.
    \item Su experiencia obtenida de su actividad práctica.
    \item Estudio de trabajo sobre el tema de autores españoles.
    \item Estudio de trabajo sobre el tema de autores extranjeros.
    \item Su propio conocimiento acerca del estado del problema en el extranjero
    \item Su intuición sobre el tema abordado.
\end{enumerate}
El nivel de competencia del experto se determina según el valor final de K. Se considera que un experto tiene alta competencia cuando K se encuentra entre 0.8 y 1, competencia moderada o media si el valor de K oscila entre 0.5 y 0.8, y baja competencia cuando K es inferior a 0.5.
\end{enumerate}





\subsection{Objetivo}
Validar el instrumento “Competencia Digital del alumnado en IA (CompDigIA)” mediante juicio de expertos en cuanto a su relevancia, representatividad y claridad.


\subsection{Instrumento}
El instrumento utilizado en la investigación es un cuestionario administrado a través de Google Forms, que recopila información sociodemográfica y profesional de los participantes, incluyendo su titulación académica, institución principal de trabajo y actividad desempeñada (docencia, investigación, gestión o técnica). Además, se indaga sobre su experiencia en la enseñanza de asignaturas relacionadas con la tecnología educativa y su participación en investigaciones o publicaciones sobre inteligencia artificial en educación. Para determinar la validez de los expertos, se calcula el Coeficiente de Competencia Experta (CCE). Posteriormente, se presentan 22 ítems que los participantes deben evaluar en función de su relevancia, representatividad y claridad, utilizando una escala Likert de 1 a 6 puntos. Todos los participantes han otorgado su consentimiento informado antes de completar el cuestionario.

\subsection{Participantes}
Una vez analizado el CCE de los 166 sujetos que contestaron el cuestionario, se decide trabajar con los que presentan un nivel de competencia alta (CCE ≥ 0.8). Por ello, la muestra queda constituida por 90 personas expertas: 54,21~\% de las personas que cumplimentaron el cuestionario.

Se destaca que la mayoría posee un doctorado (71,1~\%), seguido de aquellos con máster (17,8~\%), grado o licenciatura (8,9~\%) y, en menor proporción, diplomatura (2,2~\%).

En cuanto a la institución principal en la que trabajan, la mayoría se desempeña en centros universitarios (68,9~\%), mientras que un 24,4~\% trabaja en centros no universitarios y un 6,7~\% en empresas de formación.  

Respecto a la actividad principal, el 93,3~\% de los participantes se dedica a la docencia, mientras que el 66,7~\% realiza labores de investigación. Asimismo, un 44,4~\% se involucra en gestión y un 20~\% en actividades técnicas, lo que indica una diversidad de funciones dentro del ámbito educativo.  

El 86,7~\% ha impartido formación relacionada con Tecnología Educativa, Nuevas Tecnologías Aplicadas a la Educación, Formación a Distancia, Formación Virtual o TIC aplicadas, lo que sugiere un alto nivel de experiencia en este ámbito. Cabe destacar también que el 66,7~\% de los expertos tiene experiencia en la realización de estudios con IA en el ámbito educativo, y que hasta un 68,9~\% tiene publicaciones sobre este tema, lo que denota el alto nivel de experiencia de los seleccionados como expertos. 

\subsection{Procedimiento de análisis}
A partir de la obtención de las valoraciones por los expertos, se han calculado los estadísticos descriptivos (media y desviación típica) de los ítems que conforman el instrumento. Esto se realizó para los tres factores contemplados (relevancia, representatividad y claridad). Junto a ello, también se obtuvieron los estadísticos descriptivos para las dimensiones contempladas en el instrumento, así como una media total de todos los ítems, permitiendo así conocer la visión global de los expertos sobre el cuestionario. 


\section{Resultados}
Comenzamos con los valores que han obtenido los ítems que conforman el cuestionario en los elementos de relevancia, representatividad y claridad (\Cref{tab01}).

%% TABELA
\begin{small}
\begin{longtable}{
    >{\raggedright\arraybackslash}p{0.48\textwidth}
    llllll
    }
\caption{Nivel de relevancia, representatividad y claridad de los ítems.}
\label{tab01}
\\
\toprule

Ítems & \multicolumn{2}{>{\raggedright\arraybackslash}p{2cm}}{Relevancia} & \multicolumn{2}{>{\raggedright\arraybackslash}p{2cm}}{Representatividad} & \multicolumn{2}{>{\raggedright\arraybackslash}p{2cm}}{Claridad} \\
& M & DT & M & DT & M & DT \\
\midrule
1.1. ¿Eres capaz de buscar información en Internet utilizando
herramientas de inteligencia artificial? & 5,20 & 1,093 & 5,11 & 1,165 &
5,09 & 1,138 \\
1.2. ¿Eres capaz de saber si la información o los contenidos generados
por herramientas de inteligencia artificial son fiables y verdaderos? &
5,07 & 1,149 & 5,04 & 1,180 & 4,98 & 1,298 \\
1.3. ¿Eres capaz de organizar, guardar y encontrar la información o
contenidos que has generado con inteligencia artificial? & 5,22 & 1,079
& 5,04 & 1,180 & 5,07 & 1,279 \\
2.1. ¿Sabes utilizar herramientas de inteligencia artificial para
comunicarte e interactuar con otras personas? & 5,02 & 1,263 & 5,09 &
1,233 & 5,09 & 1,269 \\
2.2. ¿Eres capaz de compartir información o contenidos utilizando
herramientas de inteligencia artificial? & 4,93 & 1,261 & 4,96 & 1,180 &
5,09 & 1,215 \\
2.3. ¿Puedes utilizar la inteligencia artificial para realizar
actividades que tengan un beneficio para la sociedad? & 4,84 & 1,160 &
4,84 & 1,235 & 4,93 & 1,314 \\
2.4. ¿Te es útil la inteligencia artificial para trabajar en equipo? &
5,18 & 1,107 & 5,04 & 1,160 & 5,09 & 1,233 \\
2.5. Cuando utilizas herramientas de inteligencia artificial, ¿respetas
las normas de buen comportamiento y comunicación digital? (ejemplo: no
utilizar palabrotas, no cometer faltas de ortografía, etc.) & 4,96 &
1,421 & 5,00 & 1,254 & 5,18 & 1,259 \\
2.6. ¿Crees que las herramientas de inteligencia artificial pueden
ayudarte a mantener tu reputación online e identidad digital? & 4,69 &
1,387 & 4,73 & 1,413 & 4,67 & 1,438 \\
3.1. ¿Eres capaz de crear nuevos textos, imágenes o vídeos a través de
herramientas de inteligencia artificial? & 5,27 & 1,279 & 5,22 & 1,270 &
5,22 & 1,216 \\
3.2. ¿Eres capaz de modificar o mejorar contenidos digitales ya creados
gracias a herramientas de inteligencia artificial? & 5,24 & 1,125 & 5,27
& 1,110 & 5,29 & 1,114 \\
3.3. ¿Sabes cómo respetar las normas de derechos de autor y licencia de
contenidos digitales cuando utilizas herramientas de inteligencia
artificial? & 5,13 & 1,247 & 5,13 & 1,265 & 4,98 & 1,366 \\
3.4. ¿Eres capaz de resolver problemas de programación, como los que se
plantean en la asignatura de Robótica, con la ayuda de herramientas de
inteligencia artificial? & 4,82 & 1,503 & 4,73 & 1,490 & 4,76 & 1,516 \\
4.1. ¿Puede la inteligencia artificial ayudarte a proteger tus
dispositivos y contenidos digitales evitando riesgos y amenazas en
línea? & 4,84 & 1,453 & 4,82 & 1,458 & 4,76 & 1,471 \\
4.2. ¿Puede la inteligencia artificial ayudarte a proteger tu privacidad
y datos personales que puedan estar en Internet? & 4,78 & 1,497 & 4,80 &
1,493 & 4,82 & 1,518 \\
4.3. ¿Crees que las herramientas de inteligencia artificial pueden
ayudarte a proteger y mejorar tu salud tanto física como mental al usar
la tecnología? & 4,67 & 1,469 & 4,67 & 1,484 & 4,62 & 1,533 \\
4.4. ¿Crees que el uso de las herramientas de inteligencia artificial
puede ayudar a proteger el impacto que las tecnologías tienen en el
medio ambiente? Por ejemplo, ¿crees que la IA podría ayudar a reducir el
uso de energía o hacer que el reciclaje fuese más eficiente? & 4,60 &
1,444 & 4,62 & 1,503 & 4,64 & 1,546 \\
5.1. ¿Puede la IA ayudarte a resolver problemas técnicos sobre tus
dispositivos digitales? & 5,07 & 1,261 & 4,93 & 1,397 & 4,98 & 1,263 \\
5.2. ¿Puedes utilizar herramientas de IA para personalizar y ajustar a
tus necesidades entornos digitales? Por ejemplo, usar IA para hacer que
recuerdes una tarea o para elegir tu música favorita & 5,27 & 1,110 &
5,18 & 1,107 & 5,02 & 1,227 \\
5.3. ¿Eres capaz de utilizar herramientas de IA para generar contenidos
creativos digitales como, por ejemplo, dibujos, canciones, poemas, etc.?
& 5,24 & 1,164 & 5,24 & 1,145 & 5,24 & 1,164 \\
5.4. ¿Crees que hay más cosas que podrías aprender acerca del uso y la
utilidad de herramientas de inteligencia artificial? & 4,89 & 1,276 &
4,96 & 1,306 & 4,89 & 1,426 \\

\bottomrule
\source{Elaboración propia.}
\end{longtable}
\end{small}

Los resultados obtenidos reflejan una valoración generalmente positiva de los ítems en cuanto a su relevancia, representatividad y claridad, con medias en la mayoría de los casos superiores a 5 y desviaciones típicas relativamente estables. Sin embargo, se observan ciertas diferencias según el contenido del ítem. Los ítems relacionados con la creación y modificación de contenidos digitales con inteligencia artificial (ítems 3.1, 3.2 y 5.3) presentan las puntuaciones más altas en todas las dimensiones, lo que indica que los expertos los consideran altamente adecuados para evaluar la competencia digital en IA. En contraste, aquellos ítems que abordan el impacto ambiental de la IA (4.4) o su contribución a la salud (4.3) reciben las puntuaciones más bajas, lo que sugiere una menor percepción de su relevancia dentro del marco evaluado. Otro aspecto destacable es que los ítems relacionados con la protección de la identidad digital y la privacidad (2.6 y 4.2) presentan medias más bajas y mayores desviaciones típicas, lo que sugiere una menor unanimidad entre los expertos sobre su pertinencia o claridad. 

A continuación, se desglosan los datos de acuerdo con las dimensiones del instrumento (\Cref{tab02}).

%%% TABELA
\begin{small}
\begin{table}[h]
\begin{threeparttable}
\caption{Nivel de relevancia, representatividad y claridad de los ítems.}
\label{tab02}
\centering
\begin{tabular}{
    >{\raggedright\arraybackslash}p{0.4\textwidth}
    llllll
    }
\toprule
Dimensiones & \multicolumn{2}{>{\raggedright\arraybackslash}p{2cm}}{Relevancia} & \multicolumn{2}{>{\raggedright\arraybackslash}p{2.2cm}}{Representatividad} & \multicolumn{2}{>{\raggedright\arraybackslash}p{2cm}}{Claridad} \\
& M & DT & M & DT & M & DT \\
\midrule
1. Información y alfabetización digital	& 5,16 & 1,107 & 5,07 & 1,175 & 5,04 & 1,238\\
2. Comunicación y colaboración & 4,94 & 1,267 & 4,94 & 1,246 & 5,01 & 1,288\\
3. Creación de contenido digital & 5,12 & 1,289 & 5,09 & 1,284 & 5,06 & 1,303\\
4. Seguridad & 4,72 & 1,466 & 4,73 & 1,485 & 4,71 & 1,517\\
5.  Resolución de problemas	& 5,12 & 1,203 & 5,08 & 1,239 & 5,03 & 1,270\\
\bottomrule
\end{tabular}
\source{Elaboración propia.}
\end{threeparttable}
\end{table}
\end{small}

Los resultados de la tabla muestran una evaluación generalmente positiva de las dimensiones del instrumento, con medias superiores a 5 en la mayoría de los casos, excepto en la dimensión de Seguridad, que presenta las puntuaciones más bajas en todas las categorías (relevancia, representatividad y claridad), con valores cercanos a 4,7 y las desviaciones estándar más elevadas.

Cabe destacar que las medias más altas y las desviaciones estándar más bajas se han producido en las dimensiones Información y alfabetización digital y Resolución de problemas. Esto significa que los expertos consideran que los ítems de dichas dimensiones han sido correctamente formulados. Aunque con menor media en las puntuaciones y algo más de dispersión, la dimensión Creación de contenido digital alcanza valores similares a las otras dos dimensiones. Aunque con menor valoración, la dimensión Comunicación y colaboración alcanza una buena valoración en el factor claridad (5,01), siendo valorados sus ítems como comprensibles, si bien es cierto que su relevancia o representatividad es menor respecto a las dimensiones mejor valoradas.

A nivel general, considerando los estadísticos descriptivos totales del DigCompIA, obtenemos una buena consideración del instrumento. Las medias totales de relevancia (5,01), representatividad (4,98) y claridad (4,97), próximas al valor de 5, sugieren su adecuación para evaluar las competencias digitales del alumnado de Secundaria en IA. No obstante, esto debe matizarse por los resultados de las desviaciones estándar (1,266 en relevancia, 1,286 en representatividad y 1,323 en claridad), cuya variabilidad sugiere que no todos los expertos coinciden de forma plena en las valoraciones de los ítems, siendo más acuciante en la dimensión de claridad.

Esto señala que algunos ítems podrían ser percibidos de manera más ambigua o menos representativa, lo que podría requerir ajustes para reducir la discrepancia entre las evaluaciones. En definitiva, los resultados sugieren que el instrumento es sólido, pero que puede beneficiarse de una revisión para mejorar la consistencia en las valoraciones y optimizar algunos aspectos de los ítems, especialmente en lo que respecta a la claridad y la representatividad, lo cual contribuye a reducir la dispersión en las respuestas y aumentar la aceptación general.



\section{Discusión}
El propósito principal de este estudio fue validar por juicio de expertos el instrumento diseñado para evaluar la competencia digital del alumnado en inteligencia artificial. Para ello, nos basamos en el Coeficiente de Competencia Experta como criterio para la selección de los expertos. Ambos aspectos serán atendidos de forma individualizada a partir de los hallazgos que hemos realizado.

En cuanto a la selección de expertos, de una muestra inicial de 166 participantes, finalmente fueron 90 los que conformaron la muestra al obtener un nivel de competencia experta alta (CCE ≥ 0.8). Este coeficiente fue consistente con el de otros estudios que han utilizado esta técnica y dicho indicador para la validación por juicio de expertos de instrumentos en el contexto educativo \cite{cabero2021a,cabero2021b,cabero2013a,leon2024}. 

Respecto a la valoración del instrumento por juicio de expertos, el análisis de la relevancia, la representatividad y la claridad por ítems y dimensiones ha permitido constatar una evaluación positiva de la herramienta. De forma específica, la buena consideración de dimensiones como “información y alfabetización digital”, “creación de contenido digital” o “resolución de problemas” sugiere el reconocimiento de la adecuación de los ítems que conforman dichas dimensiones. Si bien considerar las áreas del DigComp y el análisis de las competencias digitales del alumnado de secundaria ha sido ya desarrollado en diferentes trabajos \cite{garciavalcarcel2020,iglesias2021}, para el uso concreto de IA tenemos menos antecedentes en la literatura científica, salvo el trabajo de \textcite{ng2024} que trabajaron en la alfabetización digital con IA. En cuanto al resto de áreas, cabe señalar las puntuaciones más bajas de algunos ítems de la dimensión “seguridad”, lo que requerirá revisar estos aspectos para su mejora. No obstante, se trata de una dimensión del DigComp que suele reportar peores niveles autopercibidos de competencia \cite{garciavalcarcel2019}. 

Por todo ello, este trabajo supone un avance significativo en la evaluación de la competencia digital para el uso de la IA en alumnado de educación secundaria, creando un cuestionario (CompDigIA) metodológicamente sólido y con respaldo tanto teórico \cite{comission2022} como de los expertos que lo han validado.



\section{Conclusiones}
La llegada de la IA ha revolucionado todos los ámbitos, incluido el educativo \cite{floresvivar2023}, tanto entre los docentes como entre el alumnado de las diferentes etapas \cite{cabero2024}. Pese a las múltiples posibilidades que ofrece su integración en los procesos de aprendizaje, existe una serie de aspectos formativos que son de capital importancia y que deben sustentar su implementación. Entre los mismos, cabe destacar la competencia digital \cite{palacios2025}, ya que las habilidades y destrezas tecnológicas de los usuarios condicionarán las experiencias y un uso más responsable y adecuado de la IA \cite{vuorikari2022}. En este sentido, es preciso conocer los niveles de competencia digital sobre el uso de la IA que tienen diferentes colectivos, como es el caso del alumnado de secundaria. 

Pese a ello, los estudios previos han trabajado ambos fenómenos de forma diferenciada, sin ofrecer una herramienta que vinculara ambas realidades de forma conjunta. Con este propósito, y tras corroborar la inexistencia previa de instrumentos que evaluaran la competencia digital y el uso de la IA en el alumnado de ese nivel educativo, se diseñó una propuesta de herramienta. Centrada en una adaptación del DigComp para integrar la IA en las áreas y subáreas del marco europeo de competencia digital, este instrumento supone una aportación específica e innovadora para dicho cometido que precisa ser validada para su utilización. Para la validación, se aplicó el juicio de expertos seleccionados por Coeficiente de Competencia Experta (CCE) \cite{cabero2013a,cabero2021a}. Los principales hallazgos se sintetizan en una valoración positiva, concretados en los niveles de relevancia, representatividad y claridad del instrumento DigCompIA en sus diferentes áreas. No obstante, al tratarse de una validación de contenido, las propuestas de mejora, centradas en la depuración de ítems del área de seguridad, deberán implementarse para futuras aplicaciones del cuestionario. 

En cuanto a las limitaciones, partiendo de que el foco ha sido una validación de contenido por juicio de expertos, es preciso referirse a la muestra utilizada. Por un lado, el número total de participantes, que podría haber sido superior para tener una visión más amplia sobre el fenómeno de estudio. Por otro lado, como su vinculación exclusiva al ámbito de la tecnología y la IA, sin contar con otros expertos educativos que puedan ofrecer su valoración pedagógica sobre el instrumento. Ambos son sesgos que pueden mejorarse y evitarse a futuro. 

Respecto a futuras líneas de investigación, se plantea seguir el proceso de validación psicométrica del instrumento, para comprobar tanto su aplicabilidad como su efectividad con estudiantes de secundaria. Junto a ello, sería interesante incorporar diferentes variables que puedan aportar contexto a los datos que obtengamos y para tomar decisiones respecto a políticas educativas y de formación, como la edad, el sexo, el acceso a la tecnología en casa o el nivel de competencia digital de las familias.

\section{Financiación}
Este estudio ha recibido financiamiento a través del Programa Estatal para la Investigación y el desarrollo Experimental, dentro del marco del Plan Estatal de Investigación Científica, Técnica y de Innovación 2024-2027 (Proyectos de Generación de Conocimiento 2024). Ministerio de Ciencia, Innovación y Universidades. Número de referencia: PID2024-155949OB-I00.

\section{Contexto de la Investigación}
Este trabajo se enmarca en la tesis doctoral de María Rubio Gragera ``Competencia digital del alumnado de Educación Secundaria: La Inteligencia Artificial como herramienta de apoyo en el proceso de enseñanza-aprendizaje)''. Programa de Doctorado Interuniversitario en Tecnología Educativa, Universidad de Málaga.

\printbibliography\label{sec-bib}
% if the text is not in Portuguese, it might be necessary to use the code below instead to print the correct ABNT abbreviations [s.n.], [s.l.]
%\begin{portuguese}
%\printbibliography[title={Bibliography}]
%\end{portuguese}


%full list: conceptualization,datacuration,formalanalysis,funding,investigation,methodology,projadm,resources,software,supervision,validation,visualization,writing,review
\begin{contributors}[sec-contributors]
\authorcontribution{Rubio-Gragera, M.}[conceptualization,investigation,writing,projadm,resources]
\authorcontribution{Palacios-Rodríguez, A.}[datacuration,supervision]
\authorcontribution{Colomo-Magaña, E.}[conceptualization,review,projadm,resources]
\end{contributors}



\begin{dataavailability}
\noindent{}\txtdataavailability{databody} % options: dataavailable, dataonly, databody, datanotav, nodata
\end{dataavailability}



\end{document}

